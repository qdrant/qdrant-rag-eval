{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23702c6-4059-4612-a04b-b49a30d2ad87",
   "metadata": {},
   "source": [
    "### **0. Import relevant packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689a9650-85e3-41b0-b92c-d7c808b71309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import openai\n",
    "import pandas as pd\n",
    "import qdrant_client\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "from typing import Optional, List, Tuple\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from llama_index.core import (\n",
    "    StorageContext\n",
    ")\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.indices.vector_store.base import VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3a0308-f753-47b2-8fb5-5af7bbde441f",
   "metadata": {},
   "source": [
    "### **1.  Retrieve the documents / dataset to be used**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e869ae8e-ea7a-4a84-825f-55c20744ec7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94f8b03f347346b09dfc266ff54d4942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HF google storage unreachable. Downloading and preparing it from source\n",
      "Downloading data: 100%|██████████| 1.78M/1.78M [00:00<00:00, 8.77MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b413f6b5264053ae574705a657cbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "dataset = load_dataset(\"atitaarora/qdrant_doc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33098945-8e7c-4c4a-9aba-9f0bd2938ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'text': Value(dtype='string', id=None), 'source': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='csv', dataset_name='qdrant_doc', config_name='default', version=0.0.0, splits={'train': SplitInfo(name='train', num_bytes=1767967, num_examples=240, shard_lengths=None, dataset_name='qdrant_doc')}, download_checksums={'hf://datasets/atitaarora/qdrant_doc@8d859890840f65337c38e96d660b81b1441bbecd/documents.csv': {'num_bytes': 1777260, 'checksum': None}}, download_size=1777260, post_processing_size=None, dataset_size=1767967, size_in_bytes=3545227)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de9ada-8966-4acd-85b0-480b792052c2",
   "metadata": {},
   "source": [
    "### **2.  Definition of global chunk properties and chunk processing**\n",
    "Processing each document with desired **TEXT_SPLITTER_ALGO , CHUNK_SIZE , CHUNK_OVERLAP** etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e464f0ad-9096-417b-8f29-1bf701f8df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global config for chunk processing\n",
    "CHUNK_SIZE = 512 #1000\n",
    "CHUNK_OVERLAP = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08a935db-68be-4b90-ad7b-13646e38dc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698b299bb495467f8c6a30be0571e71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document as LangchainDocument\n",
    "\n",
    "langchain_docs = [\n",
    "    LangchainDocument(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"]})\n",
    "    for doc in tqdm(dataset)\n",
    "]\n",
    "\n",
    "# could showcase another variation of processed documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    add_start_index=True,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
    ")\n",
    "\n",
    "docs_processed = []\n",
    "for doc in langchain_docs:\n",
    "    docs_processed += text_splitter.split_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bab102f-4f0a-4888-9f29-5a8e78366fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4431"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ab08a1-a723-45db-a371-9f03968bf63c",
   "metadata": {},
   "source": [
    "### **3. Process dataset as langchain (or llamaindex) document for further processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4e20a28-bffc-4cf0-b2c7-48be1d9c84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting Langchain document chunks above into Llamaindex Document for ingestion\n",
    "from llama_index.core import Document\n",
    "documents = [\n",
    "        Document.from_langchain_format(doc)\n",
    "        for doc in docs_processed\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e902e0fd-318a-4a7a-9f0a-0fff89d72527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4431"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee87686-b16a-4d03-a070-70c45a164042",
   "metadata": {},
   "source": [
    "### **4. Setting up Qdrant and collection**\n",
    "\n",
    "We first set up the qdrant client and then create a collection so that our data may be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9d295d5-b04f-445c-9ce1-3fa29fe897ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22207a55-ea5a-4028-b866-ca603b63d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Uncomment to initialise qdrant client in memory\n",
    "#client = qdrant_client.QdrantClient(\n",
    "#    location=\":memory:\",\n",
    "#)\n",
    "\n",
    "##Uncomment below to connect to Qdrant Cloud\n",
    "client = QdrantClient(\n",
    "    os.environ.get(\"QDRANT_URL\"), \n",
    "    api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    ")\n",
    "\n",
    "## Uncomment below to connect to local Qdrant\n",
    "#client = qdrant_client.QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54ac7bd9-b921-460e-8aea-25f19dbfe099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## General Collection level operations\n",
    "\n",
    "## Get information about existing collections\n",
    "client.get_collections()\n",
    "\n",
    "## Get information about specific collection\n",
    "#collection_info = client.get_collection(COLLECTION_NAME)\n",
    "#print(collection_info)\n",
    "\n",
    "## Deleting collection , if need be\n",
    "#client.delete_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f0956fb-37e3-438a-b1cc-a77c66c82732",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"qdrant_docs_arize_dense\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ec9eac0-0a9a-4cb5-80d4-51b035136ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-09 08:56:21.756\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfastembed.embedding\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[33m\u001b[1mDefaultEmbedding, FlagEmbedding, JinaEmbedding are deprecated.Use from fastembed import TextEmbedding instead.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dim</th>\n",
       "      <th>description</th>\n",
       "      <th>size_in_GB</th>\n",
       "      <th>sources</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAAI/bge-base-en</td>\n",
       "      <td>768</td>\n",
       "      <td>Base English model</td>\n",
       "      <td>0.420</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>768</td>\n",
       "      <td>Base English model, v1.5</td>\n",
       "      <td>0.210</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAAI/bge-large-en-v1.5</td>\n",
       "      <td>1024</td>\n",
       "      <td>Large English model, v1.5</td>\n",
       "      <td>1.200</td>\n",
       "      <td>{'hf': 'qdrant/bge-large-en-v1.5-onnx'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAAI/bge-small-en</td>\n",
       "      <td>384</td>\n",
       "      <td>Fast English model</td>\n",
       "      <td>0.130</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>384</td>\n",
       "      <td>Fast and Default English model</td>\n",
       "      <td>0.067</td>\n",
       "      <td>{'hf': 'qdrant/bge-small-en-v1.5-onnx-q'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAAI/bge-small-zh-v1.5</td>\n",
       "      <td>512</td>\n",
       "      <td>Fast and recommended Chinese model</td>\n",
       "      <td>0.090</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>384</td>\n",
       "      <td>Sentence Transformer model, MiniLM-L6-v2</td>\n",
       "      <td>0.090</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>384</td>\n",
       "      <td>Sentence Transformer model, paraphrase-multili...</td>\n",
       "      <td>0.220</td>\n",
       "      <td>{'hf': 'qdrant/paraphrase-multilingual-MiniLM-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1</td>\n",
       "      <td>768</td>\n",
       "      <td>8192 context length english model</td>\n",
       "      <td>0.520</td>\n",
       "      <td>{'hf': 'nomic-ai/nomic-embed-text-v1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1.5</td>\n",
       "      <td>768</td>\n",
       "      <td>8192 context length english model</td>\n",
       "      <td>0.520</td>\n",
       "      <td>{'hf': 'nomic-ai/nomic-embed-text-v1.5'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1024</td>\n",
       "      <td>Large general text embeddings model</td>\n",
       "      <td>1.200</td>\n",
       "      <td>{'hf': 'qdrant/gte-large-onnx'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1</td>\n",
       "      <td>1024</td>\n",
       "      <td>MixedBread Base sentence embedding model, does...</td>\n",
       "      <td>0.640</td>\n",
       "      <td>{'hf': 'mixedbread-ai/mxbai-embed-large-v1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>1024</td>\n",
       "      <td>Multilingual model, e5-large. Recommend using ...</td>\n",
       "      <td>2.240</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>768</td>\n",
       "      <td>Sentence-transformers model for tasks like clu...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{'hf': 'xenova/paraphrase-multilingual-mpnet-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-en</td>\n",
       "      <td>768</td>\n",
       "      <td>English embedding model supporting 8192 sequen...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>{'hf': 'xenova/jina-embeddings-v2-base-en'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jinaai/jina-embeddings-v2-small-en</td>\n",
       "      <td>512</td>\n",
       "      <td>English embedding model supporting 8192 sequen...</td>\n",
       "      <td>0.120</td>\n",
       "      <td>{'hf': 'xenova/jina-embeddings-v2-small-en'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model   dim  \\\n",
       "0                                    BAAI/bge-base-en   768   \n",
       "1                               BAAI/bge-base-en-v1.5   768   \n",
       "2                              BAAI/bge-large-en-v1.5  1024   \n",
       "3                                   BAAI/bge-small-en   384   \n",
       "4                              BAAI/bge-small-en-v1.5   384   \n",
       "5                              BAAI/bge-small-zh-v1.5   512   \n",
       "6              sentence-transformers/all-MiniLM-L6-v2   384   \n",
       "7   sentence-transformers/paraphrase-multilingual-...   384   \n",
       "8                        nomic-ai/nomic-embed-text-v1   768   \n",
       "9                      nomic-ai/nomic-embed-text-v1.5   768   \n",
       "10                                 thenlper/gte-large  1024   \n",
       "11                 mixedbread-ai/mxbai-embed-large-v1  1024   \n",
       "12                     intfloat/multilingual-e5-large  1024   \n",
       "13  sentence-transformers/paraphrase-multilingual-...   768   \n",
       "14                  jinaai/jina-embeddings-v2-base-en   768   \n",
       "15                 jinaai/jina-embeddings-v2-small-en   512   \n",
       "\n",
       "                                          description  size_in_GB  \\\n",
       "0                                  Base English model       0.420   \n",
       "1                            Base English model, v1.5       0.210   \n",
       "2                           Large English model, v1.5       1.200   \n",
       "3                                  Fast English model       0.130   \n",
       "4                      Fast and Default English model       0.067   \n",
       "5                  Fast and recommended Chinese model       0.090   \n",
       "6            Sentence Transformer model, MiniLM-L6-v2       0.090   \n",
       "7   Sentence Transformer model, paraphrase-multili...       0.220   \n",
       "8                   8192 context length english model       0.520   \n",
       "9                   8192 context length english model       0.520   \n",
       "10                Large general text embeddings model       1.200   \n",
       "11  MixedBread Base sentence embedding model, does...       0.640   \n",
       "12  Multilingual model, e5-large. Recommend using ...       2.240   \n",
       "13  Sentence-transformers model for tasks like clu...       1.000   \n",
       "14  English embedding model supporting 8192 sequen...       0.520   \n",
       "15  English embedding model supporting 8192 sequen...       0.120   \n",
       "\n",
       "                                              sources  \n",
       "0   {'url': 'https://storage.googleapis.com/qdrant...  \n",
       "1   {'url': 'https://storage.googleapis.com/qdrant...  \n",
       "2             {'hf': 'qdrant/bge-large-en-v1.5-onnx'}  \n",
       "3   {'url': 'https://storage.googleapis.com/qdrant...  \n",
       "4           {'hf': 'qdrant/bge-small-en-v1.5-onnx-q'}  \n",
       "5   {'url': 'https://storage.googleapis.com/qdrant...  \n",
       "6   {'url': 'https://storage.googleapis.com/qdrant...  \n",
       "7   {'hf': 'qdrant/paraphrase-multilingual-MiniLM-...  \n",
       "8              {'hf': 'nomic-ai/nomic-embed-text-v1'}  \n",
       "9            {'hf': 'nomic-ai/nomic-embed-text-v1.5'}  \n",
       "10                    {'hf': 'qdrant/gte-large-onnx'}  \n",
       "11       {'hf': 'mixedbread-ai/mxbai-embed-large-v1'}  \n",
       "12  {'url': 'https://storage.googleapis.com/qdrant...  \n",
       "13  {'hf': 'xenova/paraphrase-multilingual-mpnet-b...  \n",
       "14        {'hf': 'xenova/jina-embeddings-v2-base-en'}  \n",
       "15       {'hf': 'xenova/jina-embeddings-v2-small-en'}  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Declaring the intended Embedding Model with Fastembed\n",
    "from fastembed.embedding import TextEmbedding\n",
    "\n",
    "pd.DataFrame(TextEmbedding.list_supported_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94273d1b-1b73-44f3-aad4-c31bc3b4e1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d08a2b0f4f44a3a1a646de9c66ac05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dc6365721d41168d6014b90e0c6720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/706 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0ab242d8464db297c770d40c7c22d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7940f4d0c8a54706af26ae4bdfc4aa29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911eba64d9d24209a50e78f1922805ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446cc3754b034d9ca40f66d330af4dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a767fee6b74fe78ddf95791f926929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ort_config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15be41f9e3404a52a4a8e75f36fa4f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0cdf6d5ab594757833a3fb13d63f2ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f4faf974774293a4a6d149bba21ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_optimized.onnx:   0%|          | 0.00/66.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'BAAI/bge-small-en-v1.5'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Initilising embedding model\n",
    "embedding_model = TextEmbedding()\n",
    "\n",
    "## For custom model supported by Fastembed\n",
    "#embedding_model = TextEmbedding(model_name=\"BAAI/bge-small-en\", max_length=512)\n",
    "\n",
    "## Using Default Model - BAAI/bge-small-en-v1.5\n",
    "embedding_model.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3caf5104-04cd-469e-9098-bd9848a79f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bcb47eed3c408bbd9fec19245f90d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1936400eee144a05a625eb89e4fad270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/4431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715ba52a5e1042bb8197d8824f8e32b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a632a8ff3f88464792262891ed8b2af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2048 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750d643cf1304c589379cf0986aafa76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/335 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import llama_index\n",
    "from llama_index.core import Settings\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "## Uncomment it if you'll like to use FastEmbed instead of OpenAI\n",
    "## For the complete list of supported models ,\n",
    "##please check https://qdrant.github.io/fastembed/examples/Supported_Models/\n",
    "from llama_index.embeddings.fastembed import FastEmbedEmbedding\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=COLLECTION_NAME)\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "##Uncomment if using FastEmbed\n",
    "Settings.embed_model = FastEmbedEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "## Uncomment it if you'll like to use OpenAI Embeddings instead of FastEmbed\n",
    "#Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")\n",
    "Settings.llm = OpenAI(model=\"gpt-4-1106-preview\", temperature=0.0)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb8bccba-b0b2-490b-993f-cb0398531b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=5647)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.count(collection_name=COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7ab31f7-84c6-4e72-8acd-ef7bfd624e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "from llama_index.core.indices.vector_store import VectorIndexRetriever\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.DEFAULT,\n",
    "    similarity_top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62cd7441-cc19-4735-8cbb-cc22d7e3202f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ---\n",
      "\n",
      "title: Quantization\n",
      "\n",
      "weight: 120\n",
      "\n",
      "aliases:\n",
      "\n",
      "  - ../quantization\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "\n",
      "# Quantization\n",
      "\n",
      "\n",
      "\n",
      "Quantization is an optional feature in Qdrant that enables efficient storage and search of high-dimensional vectors.\n",
      "\n",
      "By transforming original vectors into a new representations, quantization compresses data while preserving close to original relative distances between vectors.\n",
      "\n",
      "Different quantization methods have different mechanics and tradeoffs. We will cover them in this section.\n",
      "\n",
      "2 Quantum quantization is a novel approach that leverages the power of quantum computing to speed up the search process in ANNs. By converting traditional float32 vectors into qbit vectors, we can create quantum entanglement between the qbits. Quantum entanglement is a unique phenomenon in which the states of two or more particles become interdependent, regardless of the distance between them. This property of quantum systems can be harnessed to create highly efficient vector search algorithms.\n",
      "\n",
      "3 Quantization is primarily used to reduce the memory footprint and accelerate the search process in high-dimensional vector spaces.\n",
      "\n",
      "In the context of the Qdrant, quantization allows you to optimize the search engine for specific use cases, striking a balance between accuracy, storage efficiency, and search speed.\n",
      "\n",
      "\n",
      "\n",
      "There are tradeoffs associated with quantization.\n",
      "\n",
      "On the one hand, quantization allows for significant reductions in storage requirements and faster search times.\n",
      "\n",
      "4 *Available as of v1.1.0*\n",
      "\n",
      "\n",
      "\n",
      "Scalar quantization, in the context of vector search engines, is a compression technique that compresses vectors by reducing the number of bits used to represent each vector component.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "For instance, Qdrant uses 32-bit floating numbers to represent the original vector components. Scalar quantization allows you to reduce the number of bits used to 8.\n",
      "\n",
      "In other words, Qdrant performs `float32 -> uint8` conversion for each vector component.\n",
      "\n",
      "5 Check out our [Quantum Quantization PR](https://github.com/qdrant/qdrant/pull/1639) on GitHub.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = retriever.retrieve(\"What is quantization?\")\n",
    "for i, node in enumerate(response):\n",
    "    print(i + 1, node.text, end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
