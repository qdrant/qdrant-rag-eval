{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1eaf7d-96f2-4f00-8827-beda9bed0baa",
   "metadata": {},
   "source": [
    "### **0. Import the relevant packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a40759-5a50-4b24-a5d1-2bb043d2da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup projects\n",
    "SIMPLE_RAG_PROJECT = \"simple-rag\"\n",
    "os.environ[\"PHOENIX_PROJECT_NAME\"] = SIMPLE_RAG_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "924ac3f9-3a1b-4d8d-9f38-6515f1a43501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import phoenix as px\n",
    "import nest_asyncio\n",
    "from llama_index.core import (\n",
    "    ServiceContext, StorageContext, download_loader,\n",
    "    load_index_from_storage, set_global_handler\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4749de6-8022-474a-811c-7960dfee386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import (\n",
    "    HallucinationEvaluator, OpenAIModel, QAEvaluator,\n",
    "    RelevanceEvaluator, run_evals\n",
    ")\n",
    "from phoenix.session.evaluation import get_qa_with_reference, get_retrieved_documents\n",
    "from phoenix.trace import DocumentEvaluations, SpanEvaluations\n",
    "from tqdm import tqdm\n",
    "\n",
    "import qdrant_client\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient, models\n",
    "from qdrant_client.http.models import PointStruct\n",
    "\n",
    "nest_asyncio.apply()  # needed for concurrent evals in notebook environments\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f4b83f-8400-46eb-827d-dd064ba3a319",
   "metadata": {},
   "source": [
    "### **1. Launch Phoenix**\n",
    "You can run Phoenix in the background to collect trace data emitted by any LlamaIndex application that has been instrumented with the OpenInferenceTraceCallbackHandler. Phoenix supports LlamaIndex's one-click observability which will automatically instrument your LlamaIndex application! You can consult our integration guide for a more detailed explanation of how to instrument your LlamaIndex application.\n",
    "\n",
    "Launch Phoenix and follow the instructions in the cell output to open the Phoenix UI (the UI should be empty because we have yet to run the LlamaIndex application)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74976fcc-5e86-441a-b5ce-5f840d605999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üì∫ To view the Phoenix app in a notebook, run `px.active_session().view()`\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b5a2ae-b194-402e-b23b-8b6b14332ea7",
   "metadata": {},
   "source": [
    "Be sure to enable phoenix as your global handler for tracing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15a59794-b14c-46f4-93d3-2a4993a69d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_global_handler(\"arize_phoenix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c86587-137a-4fd4-9a1f-d1c6309308f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∫ Opening a view to the Phoenix app. The app is running at http://localhost:6006/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"1000\"\n",
       "            src=\"http://localhost:6006/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2acf8c340>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view the above data in the UI\n",
    "px.active_session().view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de6b21-f9a6-46f8-89db-8d5f4fa460ef",
   "metadata": {},
   "source": [
    "### **2. Run Your Query Engine and View Your Traces in Phoenix**\n",
    "\n",
    "We've compiled a list of commonly asked questions about Qdrant. Let's download the sample queries and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc065884-7fad-4092-b94a-c3aa6c5a5c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8463bcf279bc40ad91dbebf7c364625e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/43.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125k/125k [00:00<00:00, 339kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e135f181ffbc49c7bd89ef378ab6b3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Loading the Eval dataset\n",
    "qdrant_qa = load_dataset(\"atitaarora/qdrant_docs_qna_ragas\", split=\"train\")\n",
    "qdrant_qa_question = qdrant_qa.select_columns(['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d34ec3a9-f9ae-4125-8548-9db3665c879a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What is the purpose of oversampling in Qdrant search process?',\n",
       " 'How does Qdrant address the search accuracy problem in comparison to other search engines using HNSW?',\n",
       " 'What is the difference between regular and neural search?',\n",
       " 'How can I use Qdrant as a vector store in Langchain Go?',\n",
       " 'How did Dust leverage compression features in Qdrant to manage the balance between storing vectors on disk and keeping quantized vectors in RAM effectively?',\n",
       " 'Why do we still need keyword search?',\n",
       " 'What principles did Qdrant follow while designing benchmarks for vector search engines?',\n",
       " 'What models does Qdrant support for embedding generation?',\n",
       " 'How can you parallelize the upload of a large dataset using shards in Qdrant?',\n",
       " 'What is the significance of maximizing the distance between all points in the response when utilizing vector similarity for diversity search?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_qa_question['question'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecda53d-2564-4b86-ab44-e4cd2040e840",
   "metadata": {},
   "source": [
    "### *This example uses a QdrantVectorStore and uses the previously generated collection to work fully connected with Qdrant but you can use whatever LlamaIndex application you like.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5bf79dc-8aed-41a2-ba9c-78c9af3f25b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8d118c0-e3a8-45ab-8047-e2678024e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"qdrant_docs_arize_dense\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb35c4b0-aefb-455c-b881-fdeec9da8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Uncomment to initialise qdrant client in memory\n",
    "#client = qdrant_client.QdrantClient(\n",
    "#    location=\":memory:\",\n",
    "#)\n",
    "\n",
    "##Uncomment below to connect to Qdrant Cloud\n",
    "client = QdrantClient(\n",
    "    os.environ.get(\"QDRANT_URL\"), \n",
    "    api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    ")\n",
    "\n",
    "## Uncomment below to connect to local Qdrant\n",
    "#client = qdrant_client.QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13e8ae30-d706-4ab8-9a27-7b6d302c1479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='semantic search'), CollectionDescription(name='rag-knowledge-base-MiniLM'), CollectionDescription(name='qdrant-docs'), CollectionDescription(name='knowledge-base'), CollectionDescription(name='med-db')])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a277969-5b19-465a-9e66-abb34069f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "from llama_index.core.indices.vector_store import VectorIndexRetriever\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=COLLECTION_NAME)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.DEFAULT,\n",
    "    similarity_top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd1d06-ce25-45ef-9844-8f3d7b5ebb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "for query in tqdm(qdrant_qa_question['question'][:10]):\n",
    "    try:\n",
    "      query_engine.query(query)\n",
    "      #retriever.retrieve(query)\n",
    "    except Exception as e:\n",
    "      pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
