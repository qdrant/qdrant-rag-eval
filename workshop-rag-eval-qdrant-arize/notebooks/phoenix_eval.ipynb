{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1eaf7d-96f2-4f00-8827-beda9bed0baa",
   "metadata": {},
   "source": [
    "### **0. Import the relevant packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a40759-5a50-4b24-a5d1-2bb043d2da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Setup projects\n",
    "SIMPLE_RAG_PROJECT = \"simple-rag\"\n",
    "os.environ[\"PHOENIX_PROJECT_NAME\"] = SIMPLE_RAG_PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ac3f9-3a1b-4d8d-9f38-6515f1a43501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import phoenix as px\n",
    "from phoenix.trace.llama_index import OpenInferenceTraceCallbackHandler\n",
    "import nest_asyncio\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4749de6-8022-474a-811c-7960dfee386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "nest_asyncio.apply()  # needed for concurrent evals in notebook environments\n",
    "pd.set_option(\"display.max_colwidth\", 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f4b83f-8400-46eb-827d-dd064ba3a319",
   "metadata": {},
   "source": [
    "### **1. Launch Phoenix**\n",
    "You can run Phoenix in the background to collect trace data emitted by any LlamaIndex application that has been instrumented with the OpenInferenceTraceCallbackHandler. Phoenix supports LlamaIndex's one-click observability which will automatically instrument your LlamaIndex application! You can consult our integration guide for a more detailed explanation of how to instrument your LlamaIndex application.\n",
    "\n",
    "Launch Phoenix and follow the instructions in the cell output to open the Phoenix UI (the UI should be empty because we have yet to run the LlamaIndex application)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74976fcc-5e86-441a-b5ce-5f840d605999",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = px.launch_app()\n",
    "callback_handler = OpenInferenceTraceCallbackHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c86587-137a-4fd4-9a1f-d1c6309308f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can view the above data in the UI\n",
    "session.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de6b21-f9a6-46f8-89db-8d5f4fa460ef",
   "metadata": {},
   "source": [
    "### **2. Run Your Query Engine and View Your Traces in Phoenix**\n",
    "\n",
    "We've compiled a list of commonly asked questions about Qdrant. Let's download the sample queries and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc065884-7fad-4092-b94a-c3aa6c5a5c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading the Eval dataset\n",
    "qdrant_qa = load_dataset(\"atitaarora/qdrant_docs_qna_ragas\", split=\"train\")\n",
    "qdrant_qa_question = qdrant_qa.select_columns(['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34ec3a9-f9ae-4125-8548-9db3665c879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdrant_qa_question['question'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecda53d-2564-4b86-ab44-e4cd2040e840",
   "metadata": {},
   "source": [
    "### *This example uses a QdrantVectorStore and uses the previously generated collection to work fully connected with Qdrant but you can use whatever LlamaIndex application you like.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf79dc-8aed-41a2-ba9c-78c9af3f25b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d118c0-e3a8-45ab-8047-e2678024e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"qdrant_docs_arize_dense\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35c4b0-aefb-455c-b881-fdeec9da8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Uncomment to initialise qdrant client in memory\n",
    "client = qdrant_client.QdrantClient(\n",
    "   location=\":memory:\",\n",
    ")\n",
    "\n",
    "##Uncomment below to connect to Qdrant Cloud\n",
    "# client = QdrantClient(\n",
    "#     os.environ.get(\"QDRANT_URL\"), \n",
    "#     api_key=os.environ.get(\"QDRANT_API_KEY\"),\n",
    "# )\n",
    "\n",
    "## Uncomment below to connect to local Qdrant\n",
    "#client = qdrant_client.QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8ae30-d706-4ab8-9a27-7b6d302c1479",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a277969-5b19-465a-9e66-abb34069f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "from llama_index.core.indices.vector_store import VectorIndexRetriever\n",
    "\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=COLLECTION_NAME)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "retriever = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    vector_store_query_mode=VectorStoreQueryMode.DEFAULT,\n",
    "    similarity_top_k=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd1d06-ce25-45ef-9844-8f3d7b5ebb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "for query in tqdm(qdrant_qa_question['question'][:10]):\n",
    "    try:\n",
    "      query_engine.query(query)\n",
    "      #retriever.retrieve(query)\n",
    "    except Exception as e:\n",
    "      pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
