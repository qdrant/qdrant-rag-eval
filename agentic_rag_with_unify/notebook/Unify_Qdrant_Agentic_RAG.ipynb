{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GRjSSG49A9m"
   },
   "source": [
    "# **Overcoming limitations of Naive RAG with Enhanced Agentic Approach**\n",
    "\n",
    "In this notebook, we'll explore some shortcomings of a naive RAG pipeline & build a more robust RAG system with an LLM agent that can utilize various email-tools and provide better output.\n",
    "\n",
    "We'll be using [Unify](https://unify.ai/) for querying various Large Language models. Unify simplifies the process of navigating and selecting LLMs by providing a Single Sign On (SSO) feature, which allows access to various models with a single API key. It also features **Runtime Dynamic Routing**, which *automatically redirects requests to the optimal LLM provider based on user-defined constraints.*\n",
    "\n",
    "We'll use [Qdrant](https://qdrant.tech/) for building the RAG engine. Qdrant is a vector similarity search engine that offers a user-friendly API to store, search, and manage vectors with an additional payload, supporting a wide range of applications including neural network or semantic-based matching, faceted search, and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2fOSzeU_qqJ"
   },
   "source": [
    "### **Installation**\n",
    "\n",
    "Let's start by installing some neccessary packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oo89D3Vjjnbl",
    "outputId": "4721c2de-3850-4051-e181-3d972d89aefa",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install qdrant-client fastembed unifyai python-dotenv pandas numpy==1.26.4 dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdHjTmMS_-Ao"
   },
   "source": [
    "### **Preparing the environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIivX9vmAKxE"
   },
   "source": [
    "To begin with, you need to obtain a **API key** for `Unify` as well as `Qdrant`:\n",
    " 1. You can generate your `UNIFY_KEY` from the Unify's [console page](https://console.unify.ai/login?callbackUrl=%2F).\n",
    " 2. You can get your `QDRANT_URL` and `QDRANT_API_KEY` from Qdrant's [SignUp Page](https://cloud.qdrant.io/login).\n",
    "\n",
    "Once you have generated the keys, you should store them as [Colab secrets](https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75) or if using locally in your **.env** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1vsqVkyD4NxZ"
   },
   "outputs": [],
   "source": [
    "#Uncomment this when using google colab\n",
    "#from google.colab import userdata\n",
    "#QDRANT_URL = userdata.get('QDRANT_URL')\n",
    "#QDRANT_KEY = userdata.get('QDRANT_API_KEY')\n",
    "#UNIFY_KEY = userdata.get('UNIFY_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "UNIFY_KEY=os.environ.get(\"UNIFY_KEY\")\n",
    "QDRANT_URL=os.environ.get(\"QDRANT_URL\")\n",
    "QDRANT_KEY=os.environ.get(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-ZStaiDpZNi"
   },
   "source": [
    "#### Let's instantiate our Unify & Qdrant Clients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwaNFlAd5Td1"
   },
   "source": [
    "**Note** : We can use Qdrant in 3 different listed ways, we are using **Qdrant Cloud** in this workshop today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Mz3E4ZWW5z8C"
   },
   "outputs": [],
   "source": [
    "#import qdrant_client\n",
    "##Uncomment to initialise qdrant client in memory\n",
    "#client = qdrant_client.QdrantClient(\n",
    "#    location=\":memory:\",\n",
    "#)\n",
    "\n",
    "##Uncomment below to connect to Qdrant Cloud\n",
    "#client = qdrant_client.QdrantClient(\n",
    "#    QDRANT_URL,\n",
    "#    api_key=QDRANT_KEY,\n",
    "#)\n",
    "\n",
    "## Uncomment below to connect to local Qdrant\n",
    "#client = qdrant_client.QdrantClient(\"http://localhost:6333\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "t4YdKzmHpRyu"
   },
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from unify import Unify\n",
    "\n",
    "unify_client = Unify(api_key=UNIFY_KEY, endpoint=\"llama-2-70b-chat@together-ai\")\n",
    "qdrant_client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-fQGJXHtMoY"
   },
   "source": [
    "### **Building the source dataset**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTtbx11AjoE6"
   },
   "source": [
    "We'll first craft a toy **email dataset** for John Doe, featuring exchanges with multiple entities. Our goal is to create a *compact yet diverse collection mirroring real-world email interactions*. Eventually, we'll use this data-set to build a **Q&A system** using RAG that John Doe can use *to ask questions about his emails*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "xqmeZUX_m0Fz"
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbjQcp3csTNP"
   },
   "source": [
    "**Case 1: AI Conference Invitation**\n",
    "\n",
    "An email exchange between Jane Doe and John Doe where Jane initially agreed to attend an AI conference but later canceled due to unexpected work. This was in response to an invitation from John."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "l55Ku9cwtRKb"
   },
   "outputs": [],
   "source": [
    "case_1 = [\n",
    "    {\n",
    "        'from_name': 'Jane Doe',\n",
    "        'from_email': 'janedoe@example.com',\n",
    "        'to_name': 'John Doe',\n",
    "        'to_email': 'johndoe@example.com',\n",
    "        'date': datetime.datetime(2024, 2, 27, 18, 49, 11, tzinfo=datetime.timezone.utc),\n",
    "        \"subject\": \"Re: AI Conference Invite\",\n",
    "        \"body\": \"Hey John! Sorry, something urgent has come up. I won't be able to join.\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'from_name': 'Jane Doe',\n",
    "        'from_email': 'janedoe@example.com',\n",
    "        'to_name': 'John Doe',\n",
    "        'to_email': 'johndoe@example.com',\n",
    "        'date': datetime.datetime(2024, 2, 24, 19, 42, 11, tzinfo=datetime.timezone.utc),\n",
    "        \"subject\": \"Re: AI Conference Invite\",\n",
    "        \"body\": \"Yeah, I think I should be able to join!\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'from_name': 'Jane Doe',\n",
    "        'from_email': 'janedoe@example.com',\n",
    "        'to_name': 'John Doe',\n",
    "        'to_email': 'johndoe@example.com',\n",
    "        'date': datetime.datetime(2024, 2, 23, 19, 50, 11, tzinfo=datetime.timezone.utc),\n",
    "        \"subject\": \"Re: AI Conference Invite\",\n",
    "        \"body\": \"Hmm, not sure, I'll get back to you tomorrow!\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        'from_name': 'John Doe',\n",
    "        'from_email': 'johndoe@example.com',\n",
    "        'to_name': 'Jane Doe',\n",
    "        'to_email': 'janedoe@example.com',\n",
    "        'date': datetime.datetime(2024, 2, 23, 19, 44, 11, tzinfo=datetime.timezone.utc),\n",
    "        \"subject\": \"AI Conference Invite\",\n",
    "        \"body\": \"Hi Jane, do you think you would be able to join this conference futureofaiconference.com?\"\n",
    "    },\n",
    "    {\n",
    "        'from_name': \"Future of AI\",\n",
    "        \"from_email\": \"future@ai.com\",\n",
    "        \"to_name\": \"John Doe\",\n",
    "        \"to_email\": \"johndoe@example.com\",\n",
    "        'date': datetime.datetime(2024, 2, 23, 19, 42, 11, tzinfo=datetime.timezone.utc),\n",
    "        \"subject\": \"Best AI Conferences to Attend this Year!\",\n",
    "        \"body\": \"Some of the best AI Conferences to look out for this year are awesomeAIconference and GlobalAIMeetup.\"\n",
    "     }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjT5OMX6rzZ1"
   },
   "source": [
    "**Case 2: Paper Reading Invitation Emails**\n",
    "\n",
    "In these emails, John invited Jane Smith, Alice Johnson, and Bob Smith to present their respective papers in a reading group session. Bob Smith accepted the invitation to present his paper while rest of the authers didn't reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "7gQbSAwgqj6h"
   },
   "outputs": [],
   "source": [
    "case_2 = [\n",
    "{\n",
    "    'from_name': 'John Doe',\n",
    "    'from_email': 'johndoe@example.com',\n",
    "    'to_name': 'Jane Smith',\n",
    "    'to_email': 'janesmith@google.com',\n",
    "    'date': datetime.datetime(2023, 4, 23, 19, 42, 11, tzinfo=datetime.timezone.utc),\n",
    "    \"subject\": \"Paper reading invitation\",\n",
    "    \"body\": \"\"\"Hey Jane!\n",
    "    My name is John, and I'm part of the engineering team on XYZ, I would love to ask you to present your paper 'Cool Agents stuff' on one of our reading group sessions!\"\"\"\n",
    "},\n",
    "{\n",
    "    'from_name': 'John Doe',\n",
    "    'from_email': 'johndoe@example.com',\n",
    "    'to_name': 'Alice Johnson',\n",
    "    'to_email': 'alicejohnson@microsoft.com',\n",
    "    'date': datetime.datetime(2023, 4, 23, 19, 42, 11, tzinfo=datetime.timezone.utc),\n",
    "    \"subject\": \"Paper reading invitation\",\n",
    "    \"body\": \"\"\"Hey Alice!\n",
    "    My name is John, and I'm part of the engineering team on XYZ, I would love to ask you to present your paper 'Cool Rag stuff' on one of our reading group sessions!\"\"\"\n",
    "},\n",
    "{\n",
    "   'from_name': 'Bob Smith',\n",
    "    'from_email': 'bobsmith@example.com',\n",
    "    'to_name': 'John Doe',\n",
    "    'to_email': 'johndoe@example.com',\n",
    "    'date': datetime.datetime(2023, 4, 24, 19, 42, 11, tzinfo=datetime.timezone.utc),\n",
    "    \"subject\": \"Re: Paper reading invitation\",\n",
    "    \"body\": \"\"\"Hey John!\n",
    "    I'd be happy to present!\"\"\"\n",
    "},\n",
    "{\n",
    "    'from_name': 'John Doe',\n",
    "    'from_email': 'johndoe@example.com',\n",
    "    'to_name': 'Bob Smith',\n",
    "    'to_email': 'bobsmith@unify.ai',\n",
    "    'date': datetime.datetime(2023, 4, 23, 19, 42, 11, tzinfo=datetime.timezone.utc),\n",
    "    \"subject\": \"Paper reading invitation\",\n",
    "    \"body\": \"\"\"Hey Bob!\n",
    "    My name is John, and I'm part of the engineering team on XYZ, I would love to ask you to present your paper 'Cool prompt engineering stuff' on one of our reading group sessions!\"\"\"\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9Qsk71csvjk"
   },
   "source": [
    "**Case 3: Welcome & Follow Up Emails.**\n",
    "\n",
    "An email exchange between Alex and John Doe, where Alex welcomes John Doe to NDS and expresses interest in learning how John found NDS to offer better support. Alex follows up when he doesn't receive a response. Later, the NDS Team sends John Doe an email announcing new features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "CGsgLK7xqSnx"
   },
   "outputs": [],
   "source": [
    "case_3 = [\n",
    "    {\n",
    "        'from_name': \"NDS Team\",\n",
    "        \"from_email\": \"noreply@nds.com\",\n",
    "        \"to_name\": \"John Doe\",\n",
    "        \"to_email\": \"johndoe@example.com\",\n",
    "        \"subject\": \"New Features! Nexus Dynamics Solutions\",\n",
    "        'date': datetime.datetime(2024, 3, 23, 19, 42, 11, tzinfo=datetime.timezone.utc),\n",
    "        \"body\": \"\"\"We are happy to announce our new set of features! <lots of cool features>\"\"\"\n",
    "    },\n",
    "    {\n",
    "        'from_name': \"Alex\",\n",
    "        \"from_email\": \"alex@nds.com\",\n",
    "        \"to_name\": \"John Doe\",\n",
    "        \"to_email\": \"johndoe@example.com\",\n",
    "        'date': datetime.datetime(2024, 3, 21, 20, 42, 11, tzinfo=datetime.timezone.utc),\n",
    "        \"subject\": \"Welcome to NDS!\",\n",
    "        \"body\": \"\"\"Hey John, still no reply? is it not a suitable time?\"\"\"\n",
    "    },\n",
    "    {\n",
    "        'from_name': \"Alex\",\n",
    "        \"from_email\": \"alex@nds.com\",\n",
    "        \"to_name\": \"John Doe\",\n",
    "        \"to_email\": \"johndoe@example.com\",\n",
    "        'date': datetime.datetime(2024, 3, 20, 19, 42, 11, tzinfo=datetime.timezone.utc),\n",
    "        \"subject\": \"Welcome to NDS!\",\n",
    "        \"body\": \"\"\"Hey John,\n",
    "\n",
    "        Great to see you signed up for NDS! Thought I'd introduce myself!\n",
    "\n",
    "        I'd love to know more about how you came across NDS so that we can best support you.\n",
    "\n",
    "        Would it be too difficult to connect in the coming weeks?\"\"\"\n",
    "\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er16A_I4lCZV"
   },
   "source": [
    "### **Naive RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21MDeniKBrNX"
   },
   "source": [
    "#### Building a *knowledge store* using Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyFgIQzxlbFF"
   },
   "source": [
    "Let's build a knowledge base with John's emails using Qdrant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-SLOlRNf3XMv"
   },
   "source": [
    "This code defines a custom encoder `default_encoder` that converts datetime objects to ISO formatted strings. We will need *this* custom encoder while serializing the dictionaries to JSON strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Ek0ckeyB3hnO"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def default_encoder(obj):\n",
    "    if isinstance(obj, datetime.datetime):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "y4aV65Kpum28"
   },
   "outputs": [],
   "source": [
    "email_cases = [case_1, case_2, case_3]\n",
    "email_strings = [json.dumps(email, default=default_encoder) for email in email_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_hX07wY3kZy",
    "outputId": "64433c10-06b3-4000-e354-4f4b14350c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[{\"from_name\": \"Jane Doe\", \"from_email\": \"janedoe@example.com\", \"to_name\": \"John Doe\", \"to_email\": \"johndoe@example.com\", \"date\": \"2024-02-27T18:49:11+00:00\", \"subject\": \"Re: AI Conference Invite\", \"body\": \"Hey John! Sorry, something urgent has come up. I won\\'t be able to join.\"}, {\"from_name\": \"Jane Doe\", \"from_email\": \"janedoe@example.com\", \"to_name\": \"John Doe\", \"to_email\": \"johndoe@example.com\", \"date\": \"2024-02-24T19:42:11+00:00\", \"subject\": \"Re: AI Conference Invite\", \"body\": \"Yeah, I think I should be able to join!\"}, {\"from_name\": \"Jane Doe\", \"from_email\": \"janedoe@example.com\", \"to_name\": \"John Doe\", \"to_email\": \"johndoe@example.com\", \"date\": \"2024-02-23T19:50:11+00:00\", \"subject\": \"Re: AI Conference Invite\", \"body\": \"Hmm, not sure, I\\'ll get back to you tomorrow!\"}, {\"from_name\": \"John Doe\", \"from_email\": \"johndoe@example.com\", \"to_name\": \"Jane Doe\", \"to_email\": \"janedoe@example.com\", \"date\": \"2024-02-23T19:44:11+00:00\", \"subject\": \"AI Conference Invite\", \"body\": \"Hi Jane, do you think you would be able to join this conference futureofaiconference.com?\"}, {\"from_name\": \"Future of AI\", \"from_email\": \"future@ai.com\", \"to_name\": \"John Doe\", \"to_email\": \"johndoe@example.com\", \"date\": \"2024-02-23T19:42:11+00:00\", \"subject\": \"Best AI Conferences to Attend this Year!\", \"body\": \"Some of the best AI Conferences to look out for this year are awesomeAIconference and GlobalAIMeetup.\"}]', '[{\"from_name\": \"John Doe\", \"from_email\": \"johndoe@example.com\", \"to_name\": \"Jane Smith\", \"to_email\": \"janesmith@google.com\", \"date\": \"2023-04-23T19:42:11+00:00\", \"subject\": \"Paper reading invitation\", \"body\": \"Hey Jane!\\\\n    My name is John, and I\\'m part of the engineering team on XYZ, I would love to ask you to present your paper \\'Cool Agents stuff\\' on one of our reading group sessions!\"}, {\"from_name\": \"John Doe\", \"from_email\": \"johndoe@example.com\", \"to_name\": \"Alice Johnson\", \"to_email\": \"alicejohnson@microsoft.com\", \"date\": \"2023-04-23T19:42:11+00:00\", \"subject\": \"Paper reading invitation\", \"body\": \"Hey Alice!\\\\n    My name is John, and I\\'m part of the engineering team on XYZ, I would love to ask you to present your paper \\'Cool Rag stuff\\' on one of our reading group sessions!\"}, {\"from_name\": \"Bob Smith\", \"from_email\": \"bobsmith@example.com\", \"to_name\": \"John Doe\", \"to_email\": \"johndoe@example.com\", \"date\": \"2023-04-24T19:42:11+00:00\", \"subject\": \"Re: Paper reading invitation\", \"body\": \"Hey John!\\\\n    I\\'d be happy to present!\"}, {\"from_name\": \"John Doe\", \"from_email\": \"johndoe@example.com\", \"to_name\": \"Bob Smith\", \"to_email\": \"bobsmith@unify.ai\", \"date\": \"2023-04-23T19:42:11+00:00\", \"subject\": \"Paper reading invitation\", \"body\": \"Hey Bob!\\\\n    My name is John, and I\\'m part of the engineering team on XYZ, I would love to ask you to present your paper \\'Cool prompt engineering stuff\\' on one of our reading group sessions!\"}]', '[{\"from_name\": \"NDS Team\", \"from_email\": \"noreply@nds.com\", \"to_name\": \"John Doe\", \"to_email\": \"johndoe@example.com\", \"subject\": \"New Features! Nexus Dynamics Solutions\", \"date\": \"2024-03-23T19:42:11+00:00\", \"body\": \"We are happy to announce our new set of features! <lots of cool features>\"}, {\"from_name\": \"Alex\", \"from_email\": \"alex@nds.com\", \"to_name\": \"John Doe\", \"to_email\": \"johndoe@example.com\", \"date\": \"2024-03-21T20:42:11+00:00\", \"subject\": \"Welcome to NDS!\", \"body\": \"Hey John, still no reply? is it not a suitable time?\"}, {\"from_name\": \"Alex\", \"from_email\": \"alex@nds.com\", \"to_name\": \"John Doe\", \"to_email\": \"johndoe@example.com\", \"date\": \"2024-03-20T19:42:11+00:00\", \"subject\": \"Welcome to NDS!\", \"body\": \"Hey John,\\\\n\\\\n        Great to see you signed up for NDS! Thought I\\'d introduce myself!\\\\n\\\\n        I\\'d love to know more about how you came across NDS so that we can best support you.\\\\n\\\\n        Would it be too difficult to connect in the coming weeks?\"}]']\n"
     ]
    }
   ],
   "source": [
    "print(email_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-mi9ZqE-2sMB",
    "outputId": "e81c0b49-e629-4cbd-9960-9a2384aa210c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'from_name': 'Jane Doe', 'from_email': 'janedoe@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 27, 18, 49, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: AI Conference Invite', 'body': \"Hey John! Sorry, something urgent has come up. I won't be able to join.\"}\n",
      " {'from_name': 'Jane Doe', 'from_email': 'janedoe@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 24, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: AI Conference Invite', 'body': 'Yeah, I think I should be able to join!'}\n",
      " {'from_name': 'Jane Doe', 'from_email': 'janedoe@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 23, 19, 50, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: AI Conference Invite', 'body': \"Hmm, not sure, I'll get back to you tomorrow!\"}\n",
      " {'from_name': 'John Doe', 'from_email': 'johndoe@example.com', 'to_name': 'Jane Doe', 'to_email': 'janedoe@example.com', 'date': datetime.datetime(2024, 2, 23, 19, 44, 11, tzinfo=datetime.timezone.utc), 'subject': 'AI Conference Invite', 'body': 'Hi Jane, do you think you would be able to join this conference futureofaiconference.com?'}\n",
      " {'from_name': 'Future of AI', 'from_email': 'future@ai.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 23, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Best AI Conferences to Attend this Year!', 'body': 'Some of the best AI Conferences to look out for this year are awesomeAIconference and GlobalAIMeetup.'}\n",
      " {'from_name': 'John Doe', 'from_email': 'johndoe@example.com', 'to_name': 'Jane Smith', 'to_email': 'janesmith@google.com', 'date': datetime.datetime(2023, 4, 23, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Paper reading invitation', 'body': \"Hey Jane!\\n    My name is John, and I'm part of the engineering team on XYZ, I would love to ask you to present your paper 'Cool Agents stuff' on one of our reading group sessions!\"}\n",
      " {'from_name': 'John Doe', 'from_email': 'johndoe@example.com', 'to_name': 'Alice Johnson', 'to_email': 'alicejohnson@microsoft.com', 'date': datetime.datetime(2023, 4, 23, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Paper reading invitation', 'body': \"Hey Alice!\\n    My name is John, and I'm part of the engineering team on XYZ, I would love to ask you to present your paper 'Cool Rag stuff' on one of our reading group sessions!\"}\n",
      " {'from_name': 'Bob Smith', 'from_email': 'bobsmith@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2023, 4, 24, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: Paper reading invitation', 'body': \"Hey John!\\n    I'd be happy to present!\"}\n",
      " {'from_name': 'John Doe', 'from_email': 'johndoe@example.com', 'to_name': 'Bob Smith', 'to_email': 'bobsmith@unify.ai', 'date': datetime.datetime(2023, 4, 23, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Paper reading invitation', 'body': \"Hey Bob!\\n    My name is John, and I'm part of the engineering team on XYZ, I would love to ask you to present your paper 'Cool prompt engineering stuff' on one of our reading group sessions!\"}\n",
      " {'from_name': 'NDS Team', 'from_email': 'noreply@nds.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'subject': 'New Features! Nexus Dynamics Solutions', 'date': datetime.datetime(2024, 3, 23, 19, 42, 11, tzinfo=datetime.timezone.utc), 'body': 'We are happy to announce our new set of features! <lots of cool features>'}\n",
      " {'from_name': 'Alex', 'from_email': 'alex@nds.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 3, 21, 20, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Welcome to NDS!', 'body': 'Hey John, still no reply? is it not a suitable time?'}\n",
      " {'from_name': 'Alex', 'from_email': 'alex@nds.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 3, 20, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Welcome to NDS!', 'body': \"Hey John,\\n\\n        Great to see you signed up for NDS! Thought I'd introduce myself!\\n\\n        I'd love to know more about how you came across NDS so that we can best support you.\\n\\n        Would it be too difficult to connect in the coming weeks?\"}]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Tuple, List\n",
    "\n",
    "def np_email_array(email_cases: List[List[str]]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Convert a list of email threads into numpy arrays.\n",
    "\n",
    "    Args:\n",
    "        email_cases (List[List[str]]): A list of email threads, where each thread is a list of strings.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: A tuple containing two numpy arrays:\n",
    "            - The first array contains individual emails.\n",
    "            - The second array contains string representations of emails.\n",
    "    \"\"\"\n",
    "    emails_array = []\n",
    "    emails_array_str = []\n",
    "    for thread in email_cases:\n",
    "        for email in thread:\n",
    "            emails_array_str.append(str(email))\n",
    "            emails_array.append(email)\n",
    "    return np.array(emails_array), np.array(emails_array_str)\n",
    "\n",
    "emails_array, emails_array_str = np_email_array(email_cases)\n",
    "print(emails_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzal9kU3l931"
   },
   "source": [
    "Let's extract the content and metadeta from the documents.\n",
    "We need these to create our [Qdrant collections](https://qdrant.tech/documentation/concepts/collections/) which is a fundamental way to organize data, consisting of named sets of vectors with payloads that you can search through.\n",
    "\n",
    "To help us provide seamless embedding creations throughout the workshop we are using [Fastembed](https://qdrant.github.io/fastembed/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MtMGhnJH7iTN",
    "outputId": "11af102f-cb4b-40a8-ffe7-c0e8acc584d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>dim</th>\n",
       "      <th>description</th>\n",
       "      <th>size_in_GB</th>\n",
       "      <th>sources</th>\n",
       "      <th>model_file</th>\n",
       "      <th>additional_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAAI/bge-base-en</td>\n",
       "      <td>768</td>\n",
       "      <td>Base English model</td>\n",
       "      <td>0.420</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "      <td>model_optimized.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>768</td>\n",
       "      <td>Base English model, v1.5</td>\n",
       "      <td>0.210</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "      <td>model_optimized.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAAI/bge-large-en-v1.5</td>\n",
       "      <td>1024</td>\n",
       "      <td>Large English model, v1.5</td>\n",
       "      <td>1.200</td>\n",
       "      <td>{'hf': 'qdrant/bge-large-en-v1.5-onnx'}</td>\n",
       "      <td>model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BAAI/bge-small-en</td>\n",
       "      <td>384</td>\n",
       "      <td>Fast English model</td>\n",
       "      <td>0.130</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "      <td>model_optimized.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>384</td>\n",
       "      <td>Fast and Default English model</td>\n",
       "      <td>0.067</td>\n",
       "      <td>{'hf': 'qdrant/bge-small-en-v1.5-onnx-q'}</td>\n",
       "      <td>model_optimized.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BAAI/bge-small-zh-v1.5</td>\n",
       "      <td>512</td>\n",
       "      <td>Fast and recommended Chinese model</td>\n",
       "      <td>0.090</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "      <td>model_optimized.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>384</td>\n",
       "      <td>Sentence Transformer model, MiniLM-L6-v2</td>\n",
       "      <td>0.090</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "      <td>model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>384</td>\n",
       "      <td>Sentence Transformer model, paraphrase-multili...</td>\n",
       "      <td>0.220</td>\n",
       "      <td>{'hf': 'qdrant/paraphrase-multilingual-MiniLM-...</td>\n",
       "      <td>model_optimized.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1</td>\n",
       "      <td>768</td>\n",
       "      <td>8192 context length english model</td>\n",
       "      <td>0.520</td>\n",
       "      <td>{'hf': 'nomic-ai/nomic-embed-text-v1'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1.5</td>\n",
       "      <td>768</td>\n",
       "      <td>8192 context length english model</td>\n",
       "      <td>0.520</td>\n",
       "      <td>{'hf': 'nomic-ai/nomic-embed-text-v1.5'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1.5-Q</td>\n",
       "      <td>768</td>\n",
       "      <td>Quantized 8192 context length english model</td>\n",
       "      <td>0.130</td>\n",
       "      <td>{'hf': 'nomic-ai/nomic-embed-text-v1.5'}</td>\n",
       "      <td>onnx/model_quantized.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>1024</td>\n",
       "      <td>Large general text embeddings model</td>\n",
       "      <td>1.200</td>\n",
       "      <td>{'hf': 'qdrant/gte-large-onnx'}</td>\n",
       "      <td>model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1</td>\n",
       "      <td>1024</td>\n",
       "      <td>MixedBread Base sentence embedding model, does...</td>\n",
       "      <td>0.640</td>\n",
       "      <td>{'hf': 'mixedbread-ai/mxbai-embed-large-v1'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-xs</td>\n",
       "      <td>384</td>\n",
       "      <td>Based on all-MiniLM-L6-v2 model with only 22m ...</td>\n",
       "      <td>0.090</td>\n",
       "      <td>{'hf': 'snowflake/snowflake-arctic-embed-xs'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-s</td>\n",
       "      <td>384</td>\n",
       "      <td>Based on infloat/e5-small-unsupervised, does n...</td>\n",
       "      <td>0.130</td>\n",
       "      <td>{'hf': 'snowflake/snowflake-arctic-embed-s'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-m</td>\n",
       "      <td>768</td>\n",
       "      <td>Based on intfloat/e5-base-unsupervised model, ...</td>\n",
       "      <td>0.430</td>\n",
       "      <td>{'hf': 'Snowflake/snowflake-arctic-embed-m'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-m-long</td>\n",
       "      <td>768</td>\n",
       "      <td>Based on nomic-ai/nomic-embed-text-v1-unsuperv...</td>\n",
       "      <td>0.540</td>\n",
       "      <td>{'hf': 'snowflake/snowflake-arctic-embed-m-long'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-l</td>\n",
       "      <td>1024</td>\n",
       "      <td>Based on intfloat/e5-large-unsupervised, large...</td>\n",
       "      <td>1.020</td>\n",
       "      <td>{'hf': 'snowflake/snowflake-arctic-embed-l'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>1024</td>\n",
       "      <td>Multilingual model, e5-large. Recommend using ...</td>\n",
       "      <td>2.240</td>\n",
       "      <td>{'url': 'https://storage.googleapis.com/qdrant...</td>\n",
       "      <td>model.onnx</td>\n",
       "      <td>[model.onnx_data]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>768</td>\n",
       "      <td>Sentence-transformers model for tasks like clu...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>{'hf': 'xenova/paraphrase-multilingual-mpnet-b...</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-en</td>\n",
       "      <td>768</td>\n",
       "      <td>English embedding model supporting 8192 sequen...</td>\n",
       "      <td>0.520</td>\n",
       "      <td>{'hf': 'xenova/jina-embeddings-v2-base-en'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jinaai/jina-embeddings-v2-small-en</td>\n",
       "      <td>512</td>\n",
       "      <td>English embedding model supporting 8192 sequen...</td>\n",
       "      <td>0.120</td>\n",
       "      <td>{'hf': 'xenova/jina-embeddings-v2-small-en'}</td>\n",
       "      <td>onnx/model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Qdrant/clip-ViT-B-32-text</td>\n",
       "      <td>512</td>\n",
       "      <td>CLIP text encoder</td>\n",
       "      <td>0.250</td>\n",
       "      <td>{'hf': 'Qdrant/clip-ViT-B-32-text'}</td>\n",
       "      <td>model.onnx</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model   dim  \\\n",
       "0                                    BAAI/bge-base-en   768   \n",
       "1                               BAAI/bge-base-en-v1.5   768   \n",
       "2                              BAAI/bge-large-en-v1.5  1024   \n",
       "3                                   BAAI/bge-small-en   384   \n",
       "4                              BAAI/bge-small-en-v1.5   384   \n",
       "5                              BAAI/bge-small-zh-v1.5   512   \n",
       "6              sentence-transformers/all-MiniLM-L6-v2   384   \n",
       "7   sentence-transformers/paraphrase-multilingual-...   384   \n",
       "8                        nomic-ai/nomic-embed-text-v1   768   \n",
       "9                      nomic-ai/nomic-embed-text-v1.5   768   \n",
       "10                   nomic-ai/nomic-embed-text-v1.5-Q   768   \n",
       "11                                 thenlper/gte-large  1024   \n",
       "12                 mixedbread-ai/mxbai-embed-large-v1  1024   \n",
       "13                snowflake/snowflake-arctic-embed-xs   384   \n",
       "14                 snowflake/snowflake-arctic-embed-s   384   \n",
       "15                 snowflake/snowflake-arctic-embed-m   768   \n",
       "16            snowflake/snowflake-arctic-embed-m-long   768   \n",
       "17                 snowflake/snowflake-arctic-embed-l  1024   \n",
       "18                     intfloat/multilingual-e5-large  1024   \n",
       "19  sentence-transformers/paraphrase-multilingual-...   768   \n",
       "20                  jinaai/jina-embeddings-v2-base-en   768   \n",
       "21                 jinaai/jina-embeddings-v2-small-en   512   \n",
       "22                          Qdrant/clip-ViT-B-32-text   512   \n",
       "\n",
       "                                          description  size_in_GB  \\\n",
       "0                                  Base English model       0.420   \n",
       "1                            Base English model, v1.5       0.210   \n",
       "2                           Large English model, v1.5       1.200   \n",
       "3                                  Fast English model       0.130   \n",
       "4                      Fast and Default English model       0.067   \n",
       "5                  Fast and recommended Chinese model       0.090   \n",
       "6            Sentence Transformer model, MiniLM-L6-v2       0.090   \n",
       "7   Sentence Transformer model, paraphrase-multili...       0.220   \n",
       "8                   8192 context length english model       0.520   \n",
       "9                   8192 context length english model       0.520   \n",
       "10        Quantized 8192 context length english model       0.130   \n",
       "11                Large general text embeddings model       1.200   \n",
       "12  MixedBread Base sentence embedding model, does...       0.640   \n",
       "13  Based on all-MiniLM-L6-v2 model with only 22m ...       0.090   \n",
       "14  Based on infloat/e5-small-unsupervised, does n...       0.130   \n",
       "15  Based on intfloat/e5-base-unsupervised model, ...       0.430   \n",
       "16  Based on nomic-ai/nomic-embed-text-v1-unsuperv...       0.540   \n",
       "17  Based on intfloat/e5-large-unsupervised, large...       1.020   \n",
       "18  Multilingual model, e5-large. Recommend using ...       2.240   \n",
       "19  Sentence-transformers model for tasks like clu...       1.000   \n",
       "20  English embedding model supporting 8192 sequen...       0.520   \n",
       "21  English embedding model supporting 8192 sequen...       0.120   \n",
       "22                                  CLIP text encoder       0.250   \n",
       "\n",
       "                                              sources  \\\n",
       "0   {'url': 'https://storage.googleapis.com/qdrant...   \n",
       "1   {'url': 'https://storage.googleapis.com/qdrant...   \n",
       "2             {'hf': 'qdrant/bge-large-en-v1.5-onnx'}   \n",
       "3   {'url': 'https://storage.googleapis.com/qdrant...   \n",
       "4           {'hf': 'qdrant/bge-small-en-v1.5-onnx-q'}   \n",
       "5   {'url': 'https://storage.googleapis.com/qdrant...   \n",
       "6   {'url': 'https://storage.googleapis.com/qdrant...   \n",
       "7   {'hf': 'qdrant/paraphrase-multilingual-MiniLM-...   \n",
       "8              {'hf': 'nomic-ai/nomic-embed-text-v1'}   \n",
       "9            {'hf': 'nomic-ai/nomic-embed-text-v1.5'}   \n",
       "10           {'hf': 'nomic-ai/nomic-embed-text-v1.5'}   \n",
       "11                    {'hf': 'qdrant/gte-large-onnx'}   \n",
       "12       {'hf': 'mixedbread-ai/mxbai-embed-large-v1'}   \n",
       "13      {'hf': 'snowflake/snowflake-arctic-embed-xs'}   \n",
       "14       {'hf': 'snowflake/snowflake-arctic-embed-s'}   \n",
       "15       {'hf': 'Snowflake/snowflake-arctic-embed-m'}   \n",
       "16  {'hf': 'snowflake/snowflake-arctic-embed-m-long'}   \n",
       "17       {'hf': 'snowflake/snowflake-arctic-embed-l'}   \n",
       "18  {'url': 'https://storage.googleapis.com/qdrant...   \n",
       "19  {'hf': 'xenova/paraphrase-multilingual-mpnet-b...   \n",
       "20        {'hf': 'xenova/jina-embeddings-v2-base-en'}   \n",
       "21       {'hf': 'xenova/jina-embeddings-v2-small-en'}   \n",
       "22                {'hf': 'Qdrant/clip-ViT-B-32-text'}   \n",
       "\n",
       "                   model_file   additional_files  \n",
       "0        model_optimized.onnx                NaN  \n",
       "1        model_optimized.onnx                NaN  \n",
       "2                  model.onnx                NaN  \n",
       "3        model_optimized.onnx                NaN  \n",
       "4        model_optimized.onnx                NaN  \n",
       "5        model_optimized.onnx                NaN  \n",
       "6                  model.onnx                NaN  \n",
       "7        model_optimized.onnx                NaN  \n",
       "8             onnx/model.onnx                NaN  \n",
       "9             onnx/model.onnx                NaN  \n",
       "10  onnx/model_quantized.onnx                NaN  \n",
       "11                 model.onnx                NaN  \n",
       "12            onnx/model.onnx                NaN  \n",
       "13            onnx/model.onnx                NaN  \n",
       "14            onnx/model.onnx                NaN  \n",
       "15            onnx/model.onnx                NaN  \n",
       "16            onnx/model.onnx                NaN  \n",
       "17            onnx/model.onnx                NaN  \n",
       "18                 model.onnx  [model.onnx_data]  \n",
       "19            onnx/model.onnx                NaN  \n",
       "20            onnx/model.onnx                NaN  \n",
       "21            onnx/model.onnx                NaN  \n",
       "22                 model.onnx                NaN  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To look at the complete list of supported models\n",
    "from fastembed.embedding import TextEmbedding\n",
    "import pandas as pd\n",
    "pd.DataFrame(TextEmbedding.list_supported_models())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxnrrkcL7y5O"
   },
   "source": [
    "We use the *DEFAULT_EMBEDDING_MODEL* for this workshop i.e. *BAAI/bge-small-en* however should you want to experiment with another embedding model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "zTGc94xa8La0"
   },
   "outputs": [],
   "source": [
    "#qdrant_client.DEFAULT_EMBEDDING_MODEL\n",
    "## For custom model supported by Fastembed\n",
    "#embedding_model = TextEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", max_length=384)\n",
    "#qdrant_client.set_model(embedding_model_name=embedding_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sm4oByK5DV2h",
    "outputId": "c1e75965-c5e4-49a7-ef6d-abcd68391c13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f73c7b209a4f4a8a8c2d89ea1d75cf1c',\n",
       " '4e030fafbb2547d6af0cc1d8967aa335',\n",
       " '8feaa379f2f7496cbf07e74907457c29',\n",
       " '007705a81032453dbcab08dabd2d7b04',\n",
       " 'a5ef6afd546f45438fef83c2014b55cc',\n",
       " '1964b7baba9940c18d0d9dc1604371c3',\n",
       " '98010e905fda439d9f5f8921c5173b5b',\n",
       " '893edb0b76a844e198d6c34dd83a83f7',\n",
       " 'f92c7d8b0eeb4a04be006456b76984d0',\n",
       " '280f9b1c1e964a958676f4c71a5d8c7c',\n",
       " '47a92f85bf4c42c5b0ebb1c2c9e30124',\n",
       " 'e3b0a7cdd9f54f0988c548ce8621f57b']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant_client.add(collection_name=\"email\", documents=emails_array_str, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VMBWHNBDl9C"
   },
   "source": [
    "#### Retrieval Augmented Generatation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Yg2IbvG67RQ"
   },
   "source": [
    "Now, let's define a function which will retreive the relevant context from our Qdrant collection based on the user prompt and append it to the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "PSdhm-nNiu9D"
   },
   "outputs": [],
   "source": [
    "def add_context(query, client, collection_name, limit):\n",
    "    search_result = client.query(collection_name=collection_name, query_text=query, limit=limit)\n",
    "\n",
    "    context = \"\\n\".join(r.document for r in search_result)\n",
    "    #print(context)\n",
    "    system_prompt = \"\"\"You're assisting John Doe, who has a query based on his emails.\n",
    "          Your objective is to deliver a response that is clear and concise, addressing his question while referencing pertinent information from his email threads.\n",
    "          Please keep in mind:\n",
    "          - Fully comprehend the question.\n",
    "          - For general queries (e.g., \"hi,\" \"good morning\"), respond normally without any contextual references.\n",
    "          - For specific queries related to email content, extract relevant information from the provided context.\n",
    "          - Formulate a response that directly answers the query, supported by accurate information from the relevant source.\n",
    "          - Maintain a friendly and professional tone throughout your response.\n",
    "          - If the answer cannot be found within the provided context, honestly state: \"I wasn't able to find any such information from the provided context.\"\n",
    "          \"\"\"\n",
    "\n",
    "    prompt_end = (f\"\\n\\nQuestion: {query}\\nAnswer:\")\n",
    "\n",
    "    user_prompt = f\"Context: {context}\" + prompt_end\n",
    "    return system_prompt, user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "_KnMR-1w0SSM"
   },
   "outputs": [],
   "source": [
    "def query_with_context(query, client, collection_name, retrieval_window_size):\n",
    "    system_prompt, user_prompt = add_context(query, client, collection_name, retrieval_window_size)\n",
    "    query_len = len(system_prompt) + len(user_prompt)\n",
    "    credits_before = unify_client.get_credit_balance()\n",
    "    response = unify_client.generate(\n",
    "        system_prompt=system_prompt,\n",
    "        user_prompt=user_prompt,\n",
    "    )\n",
    "    credits_after = unify_client.get_credit_balance()\n",
    "    print(\"------------------------\")\n",
    "    print(\"System's Response\")\n",
    "    print(\"------------------------\")\n",
    "    print(response)\n",
    "    print()\n",
    "    print(\"------------------------\")\n",
    "    print(f\"The length of the prompt is {query_len}\")\n",
    "    print(\"------------------------\")\n",
    "    print(f\"Credits used: {credits_before - credits_after}\")\n",
    "    print(\"------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHzWmQIFmo7b"
   },
   "source": [
    "Alright, let's now ask some questions about John's emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mX5doO-IrWCg",
    "outputId": "dbd1efdf-afc2-48cd-ecdb-bbf8823caf81"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 77.7M/77.7M [00:12<00:00, 6.25MiB/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "Sure, I can help you with that! Based on the email threads you provided, it appears that Jane Doe invited you to an AI conference and you replied asking for more information. Later, Jane apologized for the confusion and mentioned that something urgent had come up.\n",
      "\n",
      "In summary, the last few emails you received were:\n",
      "\n",
      "1. An invitation to an AI conference from Jane Doe\n",
      "2. Your response asking for more information\n",
      "3. An apology from Jane Doe for the confusion and a mention of an urgent matter\n",
      "\n",
      "I hope this summary helps! If you have any further questions or concerns, please don't hesitate to ask.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 1356\n",
      "------------------------\n",
      "Credits used: 0.00047430000000048267\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 2\n",
    "query_with_context(\"Can you summarize the last few emails I recieved?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UP0BYY4r-Yc"
   },
   "source": [
    "Clearly this **response is incorrect and unsatisfactory**.\n",
    "The latest message in John Doe's email is dated 23 March, 2024 from Nexus Dynamic Solutions. The reason why RAG fails here is because it relies on a *naive semantic matching* of the user query with the documents stored in it's database. Since the user query here doesn't explicitly mention any dates, a set of k ( retrieval window size) random documents will be retrieved by the engine.\n",
    "Let's increase the retrieval window size and see what happens ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkNQQ9WqsPIT",
    "outputId": "0776518f-e3f0-40e7-d9e3-e3011b806f07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "Sure, I can help you with that! Based on the provided context, it appears that you have received a few emails related to various topics. Here's a brief summary of the last few emails you received:\n",
      "\n",
      "1. From Jane Doe (janedoe@example.com) on September 27, 2023, with the subject \"Re: AI Conference Invite\": Jane apologizes for not being able to make it to the AI conference and mentions that something urgent has come up.\n",
      "2. From John Doe (johndoe@example.com) on March 21, 2024, with the subject \"Welcome to NDS!\": John sends an email to Jane Smith (janesmith@google.com) and copied you, welcoming you to NDS. He asks if it's not a suitable time for you to reply.\n",
      "3. From Alex (alex@nds.com) on April 24, 2024, with the subject \"Re: Paper reading invitation\": Alex invites you to present a paper and mentions that he'd be happy to do it.\n",
      "4. From John Doe (johndoe@example.com) on September 23, 2023, with the subject \"Re: AI Conference Invite\": You replied to Jane's email, saying that you're not sure about attending the conference and that you'll get back to her tomorrow.\n",
      "\n",
      "I hope that helps! Let me know if you have any further questions.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 2106\n",
      "------------------------\n",
      "Credits used: 0.0009557999999998401\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 5\n",
    "query_with_context(\"Can you summarize the last few emails I recieved?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n36iydBysSsy"
   },
   "source": [
    "The system still isn't able to find the correct email. If we increase the window size to 12 ( which means the system will retrieve all the documents), the LLM should be able to find the correct email. Let's explore this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q50M2R7BsiuE",
    "outputId": "8d506901-6d04-4754-e77f-44b940764449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "Sure, I can summarize the last few emails you received. It appears that you received an invitation to a conference from the NDS Team, which you forwarded to Jane Doe. Jane apologized for not being able to join the conference and suggested that you might be interested in attending. You replied that you would get back to her tomorrow regarding your availability. You also received an email from Alex, who expressed interest in presenting a paper at the conference. Finally, you received an email from the Future of AI, stating that they think they should be able to join the conference.\n",
      "\n",
      "Here's a summary of the last few emails you received:\n",
      "\n",
      "* NDS Team invited you to a conference.\n",
      "* You forwarded the invitation to Jane Doe.\n",
      "* Jane Doe apologized for not being able to join and suggested that you might be interested.\n",
      "* You replied that you would get back to her tomorrow regarding your availability.\n",
      "* Alex expressed interest in presenting a paper at the conference.\n",
      "* The Future of AI stated that they think they should be able to join the conference.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 2952\n",
      "------------------------\n",
      "Credits used: 0.0011825999999999226\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 12\n",
    "query_with_context(\"Can you summarize the last few emails I recieved?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BiTBkUFYniBv"
   },
   "source": [
    "As expected, the system does return the correct answer now.\n",
    "However, **at the cost of much higher input tokens**! It's also missing the dates now. Let's try another LLM!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "lrMfr3oDQVjc"
   },
   "outputs": [],
   "source": [
    "unify_client.set_endpoint(\"llama-3-70b-chat@together-ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vkt6ul7eQUox",
    "outputId": "ac752cca-a810-40ad-98f4-8d37d34ca7dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "Hi John,\n",
      "\n",
      "Based on the provided email threads, here's a summary of the last few emails you received:\n",
      "\n",
      "1. On 2024-04-24, Alex from NDS replied to your email about a paper reading invitation, mentioning they'd be happy to present.\n",
      "2. On 2024-03-21, you sent an email to Jane Smith, asking if it wasn't a suitable time, but there was no reply mentioned.\n",
      "3. On 2023-09-27, Jane Doe replied to your email about the AI Conference Invite, apologizing for something urgent that came up.\n",
      "\n",
      "These are the most recent email exchanges I could find in the provided context. Let me know if you need any further assistance!\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 2952\n",
      "------------------------\n",
      "Credits used: 0.0009143999999992047\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 12\n",
    "query_with_context(\"Can you summarize the last few emails I recieved?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNGhf5raQpW8"
   },
   "source": [
    "Another lesson here is that the final response quality also depends on the summarizing LLM.\n",
    "\n",
    "Let's try some more examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z6Eg0kSMXsLt",
    "outputId": "2ec70c0b-bd26-42fe-d132-ef69defdfa9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "Hi John!\n",
      "\n",
      "According to your email thread, Jane initially responded positively to the conference invite, saying \"Yeah, I think I should be able to join!\" However, in a later email, she mentioned that something urgent has come up and apologized, which might indicate that she may not be able to join after all.\n",
      "\n",
      "So, to answer your question, it seems uncertain whether Jane will be able to join the AI conference.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 2236\n",
      "------------------------\n",
      "Credits used: 0.0006218999999987318\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 5\n",
    "query_with_context(\"Hello! Will Jane be able to join the AI conference?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x8iDybuavM9c"
   },
   "source": [
    "Well, that's **incorrect** again.\n",
    "We know that Jane later sent another email stating that *she won't be able to join the conference*.\n",
    "If we increase the retreival window size, the system will have access to more email exchanges between John & Jane and should be able to return the correct answer.\n",
    "Let's explore this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeG_Hi6dvQce",
    "outputId": "4a595719-14d6-4534-87c5-80732fd47c26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "Hi John!\n",
      "\n",
      "According to the email thread, Jane initially responded positively to the AI Conference Invite on September 23, saying \"Yeah, I think I should be able to join!\" However, later on September 27, she sent another email apologizing and stating that something urgent has come up, implying that she might not be able to attend the conference after all.\n",
      "\n",
      "So, to answer your question, it's unclear if Jane will be able to join the AI conference.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 2236\n",
      "------------------------\n",
      "Credits used: 0.0006309000000044307\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 5\n",
    "query_with_context(\"Hello! Will Jane be able to join the AI conference?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvCzDDXyxWbf"
   },
   "source": [
    "As expected, the system does **correctly answer** the question now.\n",
    "\n",
    "The lesson here is that there's **no one-size-fits-all** value for the retrieval window size & while one does increase the accuracy of the system by choosing a large value but it comes with an increase in LLM Usage cost.\n",
    "\n",
    "Let's try another example with a different LLM now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "qOAZ4GmLRFP8"
   },
   "outputs": [],
   "source": [
    "unify_client.set_endpoint(\"gemma-7b-it@anyscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFgBN1MiSkSZ",
    "outputId": "c723b108-0809-4a34-b507-ed919a3bc4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "**Answer:**\n",
      "\n",
      "The provided text does not mention the name of the guy from Nexus Dynamic Solutions who sent emails to you, therefore I cannot answer this question.\n",
      "\n",
      "I wasn't able to find any information about the name of the guy from Nexus Dynamic Solutions that sent emails to you within the provided context.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 1514\n",
      "------------------------\n",
      "Credits used: 6.88499999981218e-05\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 2\n",
    "query_with_context(\"Hello! What was the name of the guy from Nexus Dynamic Solutions that sent me a couple of emails?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whfB4jQvS9l9",
    "outputId": "d1627a2e-6c4c-420a-a0b6-9e840eb1b4f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "Hello, John Doe,\n",
      "\n",
      "Based on the provided context, I understand your query about the name of the guy from Nexus Dynamic Solutions who sent you a couple of emails.\n",
      "\n",
      "In the email thread, the sender's name is Alex. Therefore, the answer to your question is Alex.\n",
      "\n",
      "Please let me know if you have any further questions or require further assistance.\n",
      "\n",
      "Sincerely,\n",
      "[Your Name]\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 2013\n",
      "------------------------\n",
      "Credits used: 0.0001030499999998824\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 4\n",
    "query_with_context(\"Hello! What was the name of the guy from Nexus Dynamic Solutions that sent me a couple of emails?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oH__884YTCm9",
    "outputId": "16b69f2e-5203-437f-8fb5-d0d68fb56940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "Hello, John Doe.\n",
      "\n",
      "Based on the provided context, it appears that the email threads you provided do not contain any information about the name of the guy from Nexus Dynamic Solutions who sent you a couple of emails. Therefore, I unfortunately cannot answer your query.\n",
      "\n",
      "Please provide more information or context if available, and I will be happy to assist you further.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 2525\n",
      "------------------------\n",
      "Credits used: 0.0001278000000013435\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 6\n",
    "query_with_context(\"Hello! What was the name of the guy from Nexus Dynamic Solutions that sent me a couple of emails?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCqMnM8YTF3T",
    "outputId": "5bfb371f-cb34-41bc-c7a6-8a0442562c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "**Answer:**\n",
      "\n",
      "The text does not identify the name of the guy from Nexus Dynamic Solutions who sent the emails, therefore I cannot answer this query.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 2756\n",
      "------------------------\n",
      "Credits used: 0.00013500000000021828\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 8\n",
    "query_with_context(\"Hello! What was the name of the guy from Nexus Dynamic Solutions that sent me a couple of emails?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "am-h5ta8TJ3c",
    "outputId": "486d8673-8860-4b62-a4a4-3a8af5555776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "**Answer:**\n",
      "\n",
      "The text does not provide any information about the name of the guy from Nexus Dynamic Solutions who sent you emails, therefore I cannot answer this question.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 3765\n",
      "------------------------\n",
      "Credits used: 0.00019409999999453476\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 12\n",
    "query_with_context(\"Hello! What was the name of the guy from Nexus Dynamic Solutions that sent me a couple of emails?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXioLZwyTR7z"
   },
   "source": [
    "Maybe our summarizing LLM is too weak, let's try another one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "RCoAwX2KTRPU"
   },
   "outputs": [],
   "source": [
    "unify_client.set_endpoint(\"gpt-4o@openai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKejcMUbTm1M",
    "outputId": "5e9aa629-d121-4342-b9c5-6fe441fae980"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------\n",
      "System's Response\n",
      "------------------------\n",
      "Hello! The name of the guy from Nexus Dynamics Solutions who sent you a couple of emails is Alex.\n",
      "\n",
      "------------------------\n",
      "The length of the prompt is 2013\n",
      "------------------------\n",
      "Credits used: 0.002965000000003215\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "retrieval_window_size = 4\n",
    "query_with_context(\"Hello! What was the name of the guy from Nexus Dynamic Solutions that sent me a couple of emails?\",\n",
    "                   qdrant_client,\n",
    "                   \"email\",\n",
    "                   retrieval_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXJQcWmuTqa7"
   },
   "source": [
    "Aha, GPT-4o is able to get the right answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykia8EzxJbG2"
   },
   "source": [
    "**Observation of limitations of Naive RAG**\n",
    "\n",
    "\n",
    " Let's note down some of the limitations of the **Naive RAG** system that we observed above:\n",
    "\n",
    "1. **Incomplete Information Retrieval**:\n",
    "\n",
    "  * **Issue**: Documents may **lack necessary information** to properly answer the user query.\n",
    "  * **Challenge**: Determining **optimal retrieval window size**, impacting LLM API costs.\n",
    "\n",
    "2. **Vulnerability to Vague Queries**:\n",
    "\n",
    "  * **Issue**: Naive LLM **struggles with ambiguous/polysemus user queries**.\n",
    "  * **Reason**: Direct query-document matching without robust contextual understanding.\n",
    "\n",
    "3. **Varied Response Quality:**\n",
    "\n",
    "  * **Issue**: Response quality **influenced by LLM** summarization capabilities.\n",
    "  * **Variation**: Some LLMs draw better conclusions from provided context than others.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeRfnt_7Jfuy"
   },
   "source": [
    "# **Agentic RAG**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGWJKRRMh1UV"
   },
   "source": [
    "In this section, we aim to tackle the limitations of the Naive RAG system with a **smarter LLM agent** approach.\n",
    "This enhanced approach will leverage a spectrum of email tools which we will implement, empowering the agent to respond accurately to inquiries.  \n",
    "We'll explain each part of our agent one step at a time to make it easy to follow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmYzppnJGERH"
   },
   "source": [
    "### **Utilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7idXCwdeGUWe"
   },
   "source": [
    "This section contains some useful utility methods that will need for the sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrnAebt-QfZO",
    "outputId": "fcadb65a-b776-40c4-dfd0-c54536848c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nds.com', 'microsoft.com', 'ai.com', 'example.com', 'google.com', 'unify.ai'}\n"
     ]
    }
   ],
   "source": [
    "from typing import Set, Dict\n",
    "\n",
    "def get_all_domains(email_cases: List[List[Dict[str, str]]]) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Extract unique email domains from a list of email threads.\n",
    "\n",
    "    Args:\n",
    "        email_cases (List[List[Dict[str, str]]]): A list of email threads, where each thread is a list of dictionaries representing emails.\n",
    "\n",
    "    Returns:\n",
    "        Set[str]: A set containing unique domains extracted from the emails.\n",
    "    \"\"\"\n",
    "    domains = set()\n",
    "    for thread in email_cases:\n",
    "        for email in thread:\n",
    "            if email[\"to_email\"]:\n",
    "                domains.add(email[\"to_email\"].split(\"@\")[1])\n",
    "            if email[\"from_email\"]:\n",
    "                domains.add(email[\"from_email\"].split(\"@\")[1])\n",
    "    return domains\n",
    "\n",
    "domains = get_all_domains(email_cases)\n",
    "print(domains)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGuwxfzUl3PO",
    "outputId": "8bee553e-2d20-4257-82df-984a649af25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'noreply@nds.com', 'janedoe@example.com', 'bobsmith@unify.ai', 'janesmith@google.com', 'alex@nds.com', 'alicejohnson@microsoft.com', 'johndoe@example.com', 'bobsmith@example.com', 'future@ai.com'}\n"
     ]
    }
   ],
   "source": [
    "def get_all_emails(email_cases: List[List[Dict[str, str]]]) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Extract unique email addresses from a list of email threads.\n",
    "\n",
    "    Args:\n",
    "        email_cases (List[List[Dict[str, str]]]): A list of email threads, where each thread is a list of dictionaries representing emails.\n",
    "\n",
    "    Returns:\n",
    "        Set[str]: A set containing unique email addresses extracted from the emails.\n",
    "    \"\"\"\n",
    "    all_emails = set()\n",
    "    for thread in email_cases:\n",
    "        for email in thread:\n",
    "            if email[\"to_email\"]:\n",
    "                all_emails.add(email[\"to_email\"])\n",
    "            if email[\"from_email\"]:\n",
    "                all_emails.add(email[\"from_email\"])\n",
    "    return all_emails\n",
    "\n",
    "\n",
    "all_emails = get_all_emails(email_cases)\n",
    "print(all_emails)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KiKWAsn2nPcZ"
   },
   "source": [
    "### **Tools**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Iqzp9sKEa2k"
   },
   "source": [
    "This section contains some more useful functions that our agent can use to address any user query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "daihQMAuowC1"
   },
   "outputs": [],
   "source": [
    "def search_query(query=None, subject=None, limit = 5):\n",
    "    '''Useful for fetching a bunch of emails that might be relevant to the query or email subject.\n",
    "    Make sure to include important keywords in the query to make good use of this tool.\n",
    "    The tool does not retrieve all relevant emails as it relies on fuzzy matching and semantic search, and should usually be used in combination with other tools.\n",
    "    The tool returns emails in no specific order, with no regard to its order in the original conversation, you must make sure you do not rely on it to make any final conclusions!\n",
    "    This tool does not support email\n",
    "\n",
    "    Parameters:\n",
    "    - query (str): A natural language, question-like query that will be used to find relevant emails, e.g \"name of person working at X\". Defaults to None\n",
    "    - subject (str): An email subject that can be used to retrieve other emails with similiar subject. Defaults to None\n",
    "    - limit (int): The number of emails retrieved during the search. Defaults to 5.\n",
    "\n",
    "    One of query or subject must be provided.\n",
    "  The search tool DOES NOT support gmail search operators such as \"from:\", \"label:\", etc, instead use it as it is documented above.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    A bunch of truncated relevant emails.\n",
    "    '''\n",
    "\n",
    "    emails = set()\n",
    "    if query:\n",
    "        search_result = qdrant_client.query(collection_name=\"email\", query_text=query, limit=limit)\n",
    "        return \"\\n\".join(r.document for r in search_result)\n",
    "        #q_emb = model.encode(query, normalize_embeddings=True)\n",
    "        #sim = q_emb @ name_email_subject_body_embs.T\n",
    "        #emails.update(emails_array_str[sim.argsort()[-15:]].tolist())\n",
    "    if subject:\n",
    "        idx = [i for i, email in enumerate(emails_array) if subject.lower() in email['subject'].lower()]\n",
    "        #print(idx)\n",
    "        emails.update(emails_array_str[idx])\n",
    "    return \"\\n\\n\".join(list(emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZAfFlX6NyyN",
    "outputId": "e12d7fd0-ee6c-4e34-98f3-aaf1e1715ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'from_name': 'Jane Doe', 'from_email': 'janedoe@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 27, 18, 49, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: AI Conference Invite', 'body': \"Hey John! Sorry, something urgent has come up. I won't be able to join.\"}\n",
      "\n",
      "{'from_name': 'Future of AI', 'from_email': 'future@ai.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 23, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Best AI Conferences to Attend this Year!', 'body': 'Some of the best AI Conferences to look out for this year are awesomeAIconference and GlobalAIMeetup.'}\n",
      "\n",
      "{'from_name': 'John Doe', 'from_email': 'johndoe@example.com', 'to_name': 'Jane Doe', 'to_email': 'janedoe@example.com', 'date': datetime.datetime(2024, 2, 23, 19, 44, 11, tzinfo=datetime.timezone.utc), 'subject': 'AI Conference Invite', 'body': 'Hi Jane, do you think you would be able to join this conference futureofaiconference.com?'}\n",
      "\n",
      "{'from_name': 'Jane Doe', 'from_email': 'janedoe@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 23, 19, 50, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: AI Conference Invite', 'body': \"Hmm, not sure, I'll get back to you tomorrow!\"}\n",
      "\n",
      "{'from_name': 'Jane Doe', 'from_email': 'janedoe@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 24, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: AI Conference Invite', 'body': 'Yeah, I think I should be able to join!'}\n"
     ]
    }
   ],
   "source": [
    "print(search_query(subject =\"AI conference\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzmSE_2TL7NE",
    "outputId": "5bc20cba-1c56-4867-919f-f80a10411d95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper 'Cool prompt engineering stuff' on one of our reading group sessions!\"}]\n",
      "your paper 'Cool Rag stuff' on one of our reading group sessions!\"}, {\"from_name\": \"Bob Smith\", \"from_email\": \"bobsmith@example\n",
      "paper 'Cool Agents stuff' on one of our reading group sessions!\"}, {\"from_name\": \"John Doe\", \"from_email\": \"johndoe@example\n",
      ".com\", \"date\": \"2024-04-23T19:42:11+00:00\", \"subject\": \"Paper reading invitation\", \"body\": \"Hey Alice!\\n    My name is John, and I'm part of the engineering team on XYZ, I would love to ask you to present your paper 'Cool Rag stuff' on one of our reading\n",
      ".com\", \"date\": \"2024-04-23T19:42:11+00:00\", \"subject\": \"Paper reading invitation\", \"body\": \"Hey Jane!\\n    My name is John, and I'm part of the engineering team on XYZ, I would love to ask you to present your paper 'Cool Agents stuff' on one of our reading\n"
     ]
    }
   ],
   "source": [
    "print(search_query(\"Paper Reading Session\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "rBJ4hTXAGsW2"
   },
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "mXepLAzpsdKh"
   },
   "outputs": [],
   "source": [
    "def find_email_addresses_by_entity(entity_name):\n",
    "    '''Useful for fetching emails addressess associated with an entity, can be used to know if anyone from entity has emailed the client.\n",
    "\n",
    "    Parameters:\n",
    "    - entity_name (str): Name of entity such e.g Google, Meta, MIT.\n",
    "\n",
    "    Returns:\n",
    "    List of potential email addresses associated with entity that might have interacted with the client.\n",
    "    '''\n",
    "    #llm = Unify(model=\"llama-3-70b-chat@together-ai\", temperature=0.1, api_key=UNIFY_KEY)\n",
    "    '''Useful for searching for email the client has interacted with based on the company they work at.'''\n",
    "    prompt = f\"\"\"Which of the following email domains is most likely associated with {entity_name}, return your answer as a list. Do not output anything else.\n",
    "    ```\n",
    "    # Example output\n",
    "    list: [\"domain1.com\", \"domain2.ai\"]\n",
    "    ```\n",
    "    {domains}\"\"\"\n",
    "    domains_list = unify_client.generate(user_prompt = prompt).strip(\"list:\")\n",
    "    #print(domains_list)\n",
    "    #p = ChatMessage(role=MessageRole.USER, content=prompt)\n",
    "    #a = ChatMessage(role=MessageRole.ASSISTANT, content=\"list: \")\n",
    "    #domains_list = llm.chat([p, a]).message.content.strip(\"list:\")\n",
    "    domains_list = literal_eval(domains_list.strip())\n",
    "    potential_emails = set()\n",
    "    for email in all_emails:\n",
    "        if email.split(\"@\")[1].strip() in domains_list: #and not email.split(\"@\")[1].strip().endswith(\"bounces.google.com\"):\n",
    "            potential_emails.add(email)\n",
    "    return \"Potential emails:\\n\" + \"\\n\".join(potential_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zeQFacL4ta04",
    "outputId": "14435533-c349-48bd-8850-d6591569fed3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential emails:\n",
      "noreply@nds.com\n",
      "alex@nds.com\n"
     ]
    }
   ],
   "source": [
    "print(find_email_addresses_by_entity(\"Nexus Dynamic Solutions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "kNyRls7k5Mg-"
   },
   "outputs": [],
   "source": [
    "def find_conversations(email_1, email_2, subject=None):\n",
    "    '''Useful for fetching full conversations between two email addresses to get the full picture or extra information.\n",
    "    This tool should be used to get the full context is needed for the task, it is one of the most useful tools.\n",
    "\n",
    "    Parameters:\n",
    "    - email_1 (str): first email address.\n",
    "    - email_2 (str): second email address.\n",
    "    - subject (str): Optional email subject to only return the conversation/thread with that subject. Defaults to None\n",
    "\n",
    "    Returns:\n",
    "    Full Conversations between two email addresses in chronological order.\n",
    "    '''\n",
    "    gr = []\n",
    "    for email in emails_array:\n",
    "        if (\n",
    "            email_1 in email[\"to_email\"] and email_2 in email[\"from_email\"]\n",
    "        or email_2 in email[\"to_email\"] and email_1 in email[\"from_email\"]\n",
    "        ):\n",
    "            if subject is None:\n",
    "                gr.append(email)\n",
    "            else:\n",
    "                if subject.lower().strip() in email[\"subject\"].lower().strip():\n",
    "                    gr.append(email)\n",
    "    return \"\\n\\n\".join([str(x) for x in sorted(gr, key=lambda x: x[\"date\"])][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "serlQiF6QXFy",
    "outputId": "456df6d9-c6ea-4657-d781-38de4ccaf101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'from_name': 'John Doe', 'from_email': 'johndoe@example.com', 'to_name': 'Jane Doe', 'to_email': 'janedoe@example.com', 'date': datetime.datetime(2024, 2, 23, 19, 44, 11, tzinfo=datetime.timezone.utc), 'subject': 'AI Conference Invite', 'body': 'Hi Jane, do you think you would be able to join this conference futureofaiconference.com?'}\n",
      "\n",
      "{'from_name': 'Jane Doe', 'from_email': 'janedoe@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 23, 19, 50, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: AI Conference Invite', 'body': \"Hmm, not sure, I'll get back to you tomorrow!\"}\n",
      "\n",
      "{'from_name': 'Jane Doe', 'from_email': 'janedoe@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 24, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: AI Conference Invite', 'body': 'Yeah, I think I should be able to join!'}\n",
      "\n",
      "{'from_name': 'Jane Doe', 'from_email': 'janedoe@example.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 2, 27, 18, 49, 11, tzinfo=datetime.timezone.utc), 'subject': 'Re: AI Conference Invite', 'body': \"Hey John! Sorry, something urgent has come up. I won't be able to join.\"}\n"
     ]
    }
   ],
   "source": [
    "print(find_conversations(\"johndoe@example.com\", \"janedoe@example.com\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "wIVOEAbrQxXX"
   },
   "outputs": [],
   "source": [
    "def get_emails(num_emails):\n",
    "      '''Useful for fetching the latest emails.\n",
    "      Parameters:\n",
    "      - num_emails (int): Number of latest emails to fetch.\n",
    "\n",
    "      Returns:\n",
    "      Latest `num_emails` recieved, emails are truncated if too long.\n",
    "      '''\n",
    "      return \"\\n\\n\".join([str(x) for x in sorted(emails_array, key=lambda x: x[\"date\"], reverse=True)[:num_emails]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwyMjUMikOam",
    "outputId": "237af070-50d1-44ca-fd0e-cb4a75e0bffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'from_name': 'NDS Team', 'from_email': 'noreply@nds.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'subject': 'New Features! Nexus Dynamics Solutions', 'date': datetime.datetime(2024, 3, 23, 19, 42, 11, tzinfo=datetime.timezone.utc), 'body': 'We are happy to announce our new set of features! <lots of cool features>'}\n",
      "\n",
      "{'from_name': 'Alex', 'from_email': 'alex@nds.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 3, 21, 20, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Welcome to NDS!', 'body': 'Hey John, still no reply? is it not a suitable time?'}\n",
      "\n",
      "{'from_name': 'Alex', 'from_email': 'alex@nds.com', 'to_name': 'John Doe', 'to_email': 'johndoe@example.com', 'date': datetime.datetime(2024, 3, 20, 19, 42, 11, tzinfo=datetime.timezone.utc), 'subject': 'Welcome to NDS!', 'body': \"Hey John,\\n\\n        Great to see you signed up for NDS! Thought I'd introduce myself!\\n\\n        I'd love to know more about how you came across NDS so that we can best support you.\\n\\n        Would it be too difficult to connect in the coming weeks?\"}\n"
     ]
    }
   ],
   "source": [
    "print(get_emails(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "2q0WL03zkcef"
   },
   "outputs": [],
   "source": [
    "tools = [find_conversations, find_email_addresses_by_entity, get_emails, search_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "TkcAn7tsrlJL"
   },
   "outputs": [],
   "source": [
    "tool_format = '''> Tool Name: {tool_name}\n",
    "Tool Description: {tool_desc}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Q9rOvfb-r7Dp"
   },
   "outputs": [],
   "source": [
    "formatted_tools = \"\\n\".join(tool_format.format(tool_name=t.__name__, tool_desc=t.__doc__)\n",
    "for t in tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EPAHkh4m4XB"
   },
   "source": [
    "### **Prompts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sg63ThRWX3cQ"
   },
   "source": [
    "This section contains the **system prompt** that gives the LLM instructions on how to answer the user query using the tools that we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "H58X37WBm5rZ"
   },
   "outputs": [],
   "source": [
    "sys_prompt  = \"\"\"You're assisting John Doe with the email address: johndoe@example.com, who has a query based on his emails.\n",
    "          Your objective is to deliver a response that is clear and concise,\n",
    "         addressing his question while referencing pertinent information from his email threads.\n",
    "\n",
    "\n",
    "Tools\n",
    "You have access to a wide variety of tools to help you navigate his mailbox.\n",
    "You are responsible for using the tools in any sequence you deem appropriate to complete the task at hand.\n",
    "This may require breaking the task into subtasks and using different tools to complete each subtask.\n",
    "\n",
    "You have access to the following tools:\n",
    "{formatted_tools}\n",
    "\n",
    "\n",
    "Output Format\n",
    "Please answer in the same language as the question and use the following format:\n",
    "\n",
    "Thought: Your thought process on how to tackle the question and which tool to use.\n",
    "Action: tool name (ONLY one of {tools_list}).\n",
    "Action Input: the input to the tool, in a JSON format representing the kwargs (e.g. {{\"input\": \"hello world\", \"num_beams\": 5}})\n",
    "Please ALWAYS start with a Thought.\n",
    "\n",
    "Please use a valid JSON format for the Action Input. Do NOT do this {{'input': 'hello world', 'num_beams': 5}}.\n",
    "\n",
    "If this format is used, the user will respond in the following format:\n",
    "\n",
    "Observation: tool response\n",
    "\n",
    "You should keep repeating the above format till you have enough information to answer the question without using any more tools.\n",
    "At that point, you MUST respond in the one of the following two formats:\n",
    "\n",
    "Thought: I can answer without using any more tools. I'll use the user's language to answer\n",
    "Answer: [your answer here]\n",
    "Thought: I cannot answer the question with the provided tools.\n",
    "Answer: [your answer here]\n",
    "\n",
    "Important tips you must follow:\n",
    "- Emails can be about various topics ranging from meetings, to newsletters, to other types of content, do not make premature assumptions about the question if its not clear.\n",
    "- Do not rely on expanding emails to get the full conversation between the client and other people if you need the full conversation between them, rather use the appropraite tool for that.\n",
    "- Remember that the `search` tool will only retrieve a subset of the potentially relevant emails, you will most likely need to use more tools alongside it to get the full picture.\n",
    "- You can consider using the tool responsible for searching to also search for more specific email, by passing a shared email subject, this might retrieve even more relevant emails.\n",
    "- You should never make a conclusion based on a single email, you must always retrieve the full conversation to get the full picture!\n",
    "- When you are uncertain about the information in a single email, the tool responsible for fetching the entire conversation will give you the context you need!\n",
    "- Never assume a hypothetical email domain when using any of the tools, as this will almost always lead to wrong and confusing results.\n",
    "- Try to do your best to answer the user's query instead of prematurely returning a final answer, as this provides a much better user experience to them, some tasks might require the usage of many tools and going through many emails, do not return your final response until you have exhausted your options!\n",
    "\n",
    "Current Conversation\n",
    "Below is the current user query.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "osXtru0M9Lkg"
   },
   "outputs": [],
   "source": [
    "sys_prompt = sys_prompt.format(formatted_tools=formatted_tools,\n",
    "                               tools_list=[t.__name__ for t in tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuYN7iHIqzqI"
   },
   "source": [
    "### **Agentic RAG examples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "zedNegTVDzHl"
   },
   "outputs": [],
   "source": [
    "unify_client.set_endpoint(\"claude-3-opus@anthropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "9Md2WFxrD2c8"
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "0ckDwF4LzKQm"
   },
   "outputs": [],
   "source": [
    "def generate_response(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a response to a given prompt by making use of differernt email tools.\n",
    "\n",
    "     The generation process involves multiple reasoning steps, which include extracting thoughts, actions, and observations\n",
    "     from the generated responses. The function iterates through these steps to refine the response\n",
    "     to ultimately answer the user's question.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt provided to generate the response.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If the tool action is not implemented.\n",
    "    \"\"\"\n",
    "    messages = []\n",
    "    response = unify_client.generate(user_prompt=prompt, system_prompt=sys_prompt)\n",
    "    messages.append({\"role\":\"system\", \"content\": sys_prompt})\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt })\n",
    "    # Just do a maximum of 10 reasoning steps\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            response = re.search(\"(.*?)(?=Observation:)\", response.strip(), re.DOTALL|re.MULTILINE).group(0)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        t = re.search(\"Thought: (.*)\", response).group(1)\n",
    "        print(f\"Thought: {t}...\")\n",
    "        #print(\"------------------\")\n",
    "        #print(response)\n",
    "\n",
    "        if re.search(\"Action: (.*)\", response) is not None:\n",
    "            action = re.search(\"Action: (.*)\", response).group(1).strip()\n",
    "            action_input = re.search(\"Action Input: (\\{.*?\\})\", response, flags=re.DOTALL).group(1)\n",
    "        elif re.search(\"Answer: (.*)\", response) is not None:\n",
    "            break\n",
    "\n",
    "        ips = json.loads(action_input)\n",
    "        if action == \"search_query\":\n",
    "            if \"query\" in ips:\n",
    "                output = search_query(query=ips[\"query\"])\n",
    "            else:\n",
    "                output = search_query(subject=ips[\"subject\"])\n",
    "\n",
    "        elif action == \"find_conversations\":\n",
    "            if \"subject\" in ips:\n",
    "                output = find_conversations(email_1=ips[\"email_1\"], email_2=ips[\"email_2\"], subject=ips[\"subject\"])\n",
    "            else:\n",
    "                output = find_conversations(email_1=ips[\"email_1\"], email_2=ips[\"email_2\"])\n",
    "\n",
    "        elif action == \"find_email_addresses_by_entity\":\n",
    "            output = find_email_addresses_by_entity(entity_name=ips[\"entity_name\"])\n",
    "\n",
    "        elif action == \"get_emails\":\n",
    "            output = get_emails(num_emails=ips[\"num_emails\"])\n",
    "        else:\n",
    "            raise Exception(\"Tool is not implemented\", action)\n",
    "\n",
    "        tool_observation = f'''Observation:\n",
    "        {output}'''\n",
    "        messages.append({'role': 'assistant', \"content\": response})\n",
    "        messages.append({'role': 'user', 'content': tool_observation})\n",
    "        response = unify_client.generate(messages=messages, system_prompt=sys_prompt)\n",
    "\n",
    "    answer = re.search(\"Answer: (.*)\", response, flags=re.DOTALL).group(1)\n",
    "    print(\"Answer: \", answer)\n",
    "    #return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_8tUMT2GGhr",
    "outputId": "4bafdba8-acdc-4037-fc8e-0a1ae11dac85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To summarize the latest emails, I will use the `get_emails` tool to retrieve the 5 most recent emails. This should give me a good overview of the client's recent email activity....\n",
      "Thought: The 5 latest emails show a range of topics. There are 3 emails related to NDS, which seems to be a new service John signed up for. Alex from NDS reached out twice to connect with John, but it's unclear if John has responded yet. There's also an email about new NDS features being announced....\n",
      "Answer:  Based on the 5 most recent emails:\n",
      "\n",
      "- You signed up for a service called NDS (Nexus Dynamics Solutions). Alex from NDS has reached out twice to connect with you and learn more about how you found their service, but it's unclear if you've replied yet. NDS also sent an announcement email about new features being released.\n",
      "\n",
      "- You had an email exchange with Jane Doe regarding an AI conference invite. She initially said she could attend, but in her latest email had to cancel due to an urgent issue that came up.\n",
      "\n",
      "Let me know if you need any other details about these emails!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Can you summarize the last few emails I recieved?\"\n",
    "generate_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ye3_FrHZthuC",
    "outputId": "45d8dc25-4756-4e31-a653-7cb0dee0aac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To determine if Jane will be able to attend the AI conference, I should search for emails related to Jane and the conference. The search_query tool can help find relevant emails....\n",
      "Thought: The search results provide some relevant information about Jane's attendance at the AI conference, but the emails are not in chronological order and there seems to be a conversation between Jane and John that is not fully captured. To get a clearer picture, I should use the find_conversations tool to retrieve the full thread between Jane and John about the AI conference....\n",
      "Thought: Based on the full conversation between Jane and John about the AI conference, it appears that:...\n",
      "Answer:  No, based on the email conversation, Jane will not be able to attend the AI conference. Although she initially thought she could join when John invited her, she later informed him that due to an urgent matter that came up, she won't be able to attend the conference.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Hey! Will Jane be able to attend the AI conference?\"\n",
    "generate_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhW6Nbs57-Gz",
    "outputId": "0c30f3dd-9307-4615-9948-3f1907ce1f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To answer this query, I will need to find emails related to the paper reading invitation and see which researchers accepted or declined the invitation. I should start by searching for relevant emails using keywords from the query....\n",
      "Thought: The search results provide some relevant information about the paper reading invitations sent out and the responses. However, to get a clear picture of who accepted and declined, I will need to find the full conversation threads for each researcher invited....\n",
      "Thought: The search did not return the full conversation with Alice from Anthropic. I will try searching for another researcher's conversation....\n",
      "Thought: It seems there are no email conversations found with the researchers invited based on the initial search results. To get more information, I will try a broader search for emails related to \"paper reading\"....\n",
      "Thought: The new search results show the initial invitations sent to Alice, Jane, and Bob to present their papers at the reading group sessions. To determine who accepted or declined, I should search for their individual responses using the subject \"Re: Paper reading invitation\"....\n",
      "Thought: The search result shows that Bob Smith accepted the paper reading invitation. However, I don't see responses from Alice or Jane. To confirm if they responded, I will search for their full conversation threads....\n",
      "Thought: No conversation found with Alice regarding the paper reading invitation. I'll check for Jane's response as well....\n",
      "Thought: I can answer without using any more tools. I'll use the user's language to answer....\n",
      "Answer:  Based on the email threads, it appears that:\n",
      "\n",
      "Bob Smith from bobsmith@example.com accepted your paper reading invitation to present his paper \"Cool prompt engineering stuff\". \n",
      "\n",
      "However, I did not find any responses from Alice at alice@anthropic.com regarding your invitation to present her paper \"Cool Rag stuff\", or from Jane at janedoe@example.com for her paper \"Cool Agents stuff\".\n",
      "\n",
      "So in summary:\n",
      "- Bob Smith accepted \n",
      "- No confirmation if Alice or Jane accepted or declined, as their responses were not found in the provided emails.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Who are the researchers (and their papers) that accepted and declined my Paper reading invitation?\"\n",
    "generate_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42tysGvRHcrM",
    "outputId": "27bd5b44-7126-41c6-e506-efafe60cd2ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To find the name of the person from Nexus Dynamic Solutions who sent emails, I should first search for emails mentioning the company to see if any conversations took place. If I find a relevant email, I can then use the find_conversations tool to retrieve the full email thread and look for the person's name....\n",
      "Thought: The search results show that there were a couple of emails from Nexus Dynamic Solutions, specifically from someone named Alex. To get Alex's full name and confirm he was the only one who emailed me from NDS, I should find the full conversation thread with him....\n",
      "Thought: Based on the full conversation thread, it looks like Alex Nexus was the only person from Nexus Dynamic Solutions who emailed me. He sent a couple of welcome emails after I signed up for their service. I have enough information to provide a final answer to the original question....\n",
      "Answer:  The person from Nexus Dynamic Solutions who sent you a couple of emails is Alex Nexus. He reached out to welcome you after you signed up for their service.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What was the name of the guy from Nexus Dynamic Solutions that sent me a couple of emails?\"\n",
    "generate_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTvlkrFaK2Y0"
   },
   "source": [
    "# Limitations of Agentic RAG\n",
    "\n",
    "Getting LLMs to adhere to the system prompt's instructions is extremely challenging. It requires meticulous fine-tuning of the system prompt through testing numerous examples. Furthermore, a system prompt that is effective with one model may not necessarily be effective with others. Let's explore this now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "pc5W6MWOKtnW"
   },
   "outputs": [],
   "source": [
    "unify_client.set_endpoint(\"llama-2-70b-chat@together-ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "1nQ81yUdKwoc",
    "outputId": "5dfa8822-8b06-4708-fbbd-4979c718b66b"
   },
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'detail': '<!DOCTYPE html>\\n<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\\n<head>\\n\\n\\n<title>api.together.xyz | 524: A timeout occurred</title>\\n<meta charset=\"UTF-8\" />\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\\n<meta name=\"robots\" content=\"noindex, nofollow\" />\\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\\n<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\\n\\n\\n</head>\\n<body>\\n<div id=\"cf-wrapper\">\\n    <div id=\"cf-error-details\" class=\"p-0\">\\n        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\\n            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\\n              <span class=\"inline-block\">A timeout occurred</span>\\n              <span class=\"code-label\">Error code 524</span>\\n            </h1>\\n            <div>\\n               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\\n            </div>\\n            <div class=\"mt-3\">2024-06-13 16:42:03 UTC</div>\\n        </header>\\n        <div class=\"my-8 bg-gradient-gray\">\\n            <div class=\"w-240 lg:w-full mx-auto\">\\n                <div class=\"clearfix md:px-8\">\\n                  \\n<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    \\n    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    \\n  </div>\\n  <span class=\"md:block w-full truncate\">You</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    \\n    Browser\\n    \\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\\n</div>\\n\\n<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">\\n    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    </a>\\n  </div>\\n  <span class=\"md:block w-full truncate\">London</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">\\n    Cloudflare\\n    </a>\\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\\n</div>\\n\\n<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    \\n    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    \\n  </div>\\n  <span class=\"md:block w-full truncate\">api.together.xyz</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    \\n    Host\\n    \\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\\n</div>\\n\\n                </div>\\n            </div>\\n        </div>\\n\\n        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\\n            <div class=\"clearfix\">\\n                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\\n                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\\n                    <p>The origin web server timed out responding to this request.</p>\\n                </div>\\n                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\\n                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\\n                          <h3 class=\"text-15 font-semibold mb-2\">If you\\'re a visitor of this website:</h3>\\n      <p class=\"mb-6\">Please try again in a few minutes.</p>\\n\\n      <h3 class=\"text-15 font-semibold mb-2\">If you\\'re the owner of this website:</h3>\\n      <p><span>The connection to the origin web server was made, but the origin web server timed out before responding. The likely cause is an overloaded background task, database or application, stressing the resources on your web server. To resolve, please work with your hosting provider or web development team to free up resources for your database or overloaded application.</span> <a rel=\"noopener noreferrer\" href=\"https://support.cloudflare.com/hc/en-us/articles/200171926-Error-524\">Additional troubleshooting information here.</a></p>\\n                </div>\\n            </div>\\n        </div>\\n\\n        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\\n  <p class=\"text-13\">\\n    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">893385ab597a2402</strong></span>\\n    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\\n    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\\n      Your IP:\\n      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\\n      <span class=\"hidden\" id=\"cf-footer-ip\">2600:1900:2000:93::1:2501</span>\\n      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\\n    </span>\\n    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=api.together.xyz\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\\n    \\n  </p>\\n  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\\n</div><!-- /.error-footer -->\\n\\n\\n    </div>\\n</div>\\n</body>\\n</html>'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat was the name of the guy from Nexus Dynamic Solutions that sent me a couple of emails?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[76], line 19\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mGenerate a response to a given prompt by making use of differernt email tools.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Exception: If the tool action is not implemented.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m messages \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 19\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43munify_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: sys_prompt})\n\u001b[1;32m     21\u001b[0m messages\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt })\n",
      "File \u001b[0;32m~/qdrant/workspace/qdrant-rag-eval/agentic_rag_with_unify/unify/lib/python3.9/site-packages/unify/clients.py:183\u001b[0m, in \u001b[0;36mUnify.generate\u001b[0;34m(self, user_prompt, system_prompt, messages, max_tokens, temperature, stop, stream)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_stream(contents, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_endpoint,\n\u001b[1;32m    180\u001b[0m                                   max_tokens\u001b[38;5;241m=\u001b[39mmax_tokens,\n\u001b[1;32m    181\u001b[0m                                   temperature\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m    182\u001b[0m                                   stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_non_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/qdrant/workspace/qdrant-rag-eval/agentic_rag_with_unify/unify/lib/python3.9/site-packages/unify/clients.py:264\u001b[0m, in \u001b[0;36mUnify._generate_non_stream\u001b[0;34m(self, messages, endpoint, max_tokens, temperature, stop)\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chat_completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore # noqa: E501, WPS219\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mAPIStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m status_error_map[e\u001b[38;5;241m.\u001b[39mstatus_code](e\u001b[38;5;241m.\u001b[39mmessage) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'detail': '<!DOCTYPE html>\\n<!--[if lt IE 7]> <html class=\"no-js ie6 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if IE 7]>    <html class=\"no-js ie7 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if IE 8]>    <html class=\"no-js ie8 oldie\" lang=\"en-US\"> <![endif]-->\\n<!--[if gt IE 8]><!--> <html class=\"no-js\" lang=\"en-US\"> <!--<![endif]-->\\n<head>\\n\\n\\n<title>api.together.xyz | 524: A timeout occurred</title>\\n<meta charset=\"UTF-8\" />\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\\n<meta name=\"robots\" content=\"noindex, nofollow\" />\\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1\" />\\n<link rel=\"stylesheet\" id=\"cf_styles-css\" href=\"/cdn-cgi/styles/main.css\" />\\n\\n\\n</head>\\n<body>\\n<div id=\"cf-wrapper\">\\n    <div id=\"cf-error-details\" class=\"p-0\">\\n        <header class=\"mx-auto pt-10 lg:pt-6 lg:px-8 w-240 lg:w-full mb-8\">\\n            <h1 class=\"inline-block sm:block sm:mb-2 font-light text-60 lg:text-4xl text-black-dark leading-tight mr-2\">\\n              <span class=\"inline-block\">A timeout occurred</span>\\n              <span class=\"code-label\">Error code 524</span>\\n            </h1>\\n            <div>\\n               Visit <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">cloudflare.com</a> for more information.\\n            </div>\\n            <div class=\"mt-3\">2024-06-13 16:42:03 UTC</div>\\n        </header>\\n        <div class=\"my-8 bg-gradient-gray\">\\n            <div class=\"w-240 lg:w-full mx-auto\">\\n                <div class=\"clearfix md:px-8\">\\n                  \\n<div id=\"cf-browser-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    \\n    <span class=\"cf-icon-browser block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    \\n  </div>\\n  <span class=\"md:block w-full truncate\">You</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    \\n    Browser\\n    \\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\\n</div>\\n\\n<div id=\"cf-cloudflare-status\" class=\" relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">\\n    <span class=\"cf-icon-cloud block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-ok w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    </a>\\n  </div>\\n  <span class=\"md:block w-full truncate\">London</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    <a href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=api.together.xyz\" target=\"_blank\" rel=\"noopener noreferrer\">\\n    Cloudflare\\n    </a>\\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-green-success\">Working</span>\\n</div>\\n\\n<div id=\"cf-host-status\" class=\"cf-error-source relative w-1/3 md:w-full py-15 md:p-0 md:py-8 md:text-left md:border-solid md:border-0 md:border-b md:border-gray-400 overflow-hidden float-left md:float-none text-center\">\\n  <div class=\"relative mb-10 md:m-0\">\\n    \\n    <span class=\"cf-icon-server block md:hidden h-20 bg-center bg-no-repeat\"></span>\\n    <span class=\"cf-icon-error w-12 h-12 absolute left-1/2 md:left-auto md:right-0 md:top-0 -ml-6 -bottom-4\"></span>\\n    \\n  </div>\\n  <span class=\"md:block w-full truncate\">api.together.xyz</span>\\n  <h3 class=\"md:inline-block mt-3 md:mt-0 text-2xl text-gray-600 font-light leading-1.3\">\\n    \\n    Host\\n    \\n  </h3>\\n  <span class=\"leading-1.3 text-2xl text-red-error\">Error</span>\\n</div>\\n\\n                </div>\\n            </div>\\n        </div>\\n\\n        <div class=\"w-240 lg:w-full mx-auto mb-8 lg:px-8\">\\n            <div class=\"clearfix\">\\n                <div class=\"w-1/2 md:w-full float-left pr-6 md:pb-10 md:pr-0 leading-relaxed\">\\n                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What happened?</h2>\\n                    <p>The origin web server timed out responding to this request.</p>\\n                </div>\\n                <div class=\"w-1/2 md:w-full float-left leading-relaxed\">\\n                    <h2 class=\"text-3xl font-normal leading-1.3 mb-4\">What can I do?</h2>\\n                          <h3 class=\"text-15 font-semibold mb-2\">If you\\'re a visitor of this website:</h3>\\n      <p class=\"mb-6\">Please try again in a few minutes.</p>\\n\\n      <h3 class=\"text-15 font-semibold mb-2\">If you\\'re the owner of this website:</h3>\\n      <p><span>The connection to the origin web server was made, but the origin web server timed out before responding. The likely cause is an overloaded background task, database or application, stressing the resources on your web server. To resolve, please work with your hosting provider or web development team to free up resources for your database or overloaded application.</span> <a rel=\"noopener noreferrer\" href=\"https://support.cloudflare.com/hc/en-us/articles/200171926-Error-524\">Additional troubleshooting information here.</a></p>\\n                </div>\\n            </div>\\n        </div>\\n\\n        <div class=\"cf-error-footer cf-wrapper w-240 lg:w-full py-10 sm:py-4 sm:px-8 mx-auto text-center sm:text-left border-solid border-0 border-t border-gray-300\">\\n  <p class=\"text-13\">\\n    <span class=\"cf-footer-item sm:block sm:mb-1\">Cloudflare Ray ID: <strong class=\"font-semibold\">893385ab597a2402</strong></span>\\n    <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\\n    <span id=\"cf-footer-item-ip\" class=\"cf-footer-item hidden sm:block sm:mb-1\">\\n      Your IP:\\n      <button type=\"button\" id=\"cf-footer-ip-reveal\" class=\"cf-footer-ip-reveal-btn\">Click to reveal</button>\\n      <span class=\"hidden\" id=\"cf-footer-ip\">2600:1900:2000:93::1:2501</span>\\n      <span class=\"cf-footer-separator sm:hidden\">&bull;</span>\\n    </span>\\n    <span class=\"cf-footer-item sm:block sm:mb-1\"><span>Performance &amp; security by</span> <a rel=\"noopener noreferrer\" href=\"https://www.cloudflare.com/5xx-error-landing?utm_source=errorcode_524&utm_campaign=api.together.xyz\" id=\"brand_link\" target=\"_blank\">Cloudflare</a></span>\\n    \\n  </p>\\n  <script>(function(){function d(){var b=a.getElementById(\"cf-footer-item-ip\"),c=a.getElementById(\"cf-footer-ip-reveal\");b&&\"classList\"in b&&(b.classList.remove(\"hidden\"),c.addEventListener(\"click\",function(){c.classList.add(\"hidden\");a.getElementById(\"cf-footer-ip\").classList.remove(\"hidden\")}))}var a=document;document.addEventListener&&a.addEventListener(\"DOMContentLoaded\",d)})();</script>\\n</div><!-- /.error-footer -->\\n\\n\\n    </div>\\n</div>\\n</body>\\n</html>'}"
     ]
    }
   ],
   "source": [
    "prompt = \"What was the name of the guy from Nexus Dynamic Solutions that sent me a couple of emails?\"\n",
    "generate_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4VfJbnmMv4h"
   },
   "source": [
    "The failure occurred because the response from `llama-2-70b-chat` did not include the string \"Action Input\", despite the system prompt's explicit instruction to always contain the function arguments after \"Action Input\" string. It's important to clarify that this doesn't necessarily indicate `llama-2-70b-chat`'s inability to adhere to the system prompt. Instead, it suggests that the system prompt may require adjustments to be compatible with it. Let's try with some other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "lu4srbYpMUIo"
   },
   "outputs": [],
   "source": [
    "unify_client.set_endpoint(\"mixtral-8x7b-instruct-v0.1@together-ai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "2gFIf6OeSu1Y",
    "outputId": "79425bf8-c042-4275-8a41-ef70a8ba1b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: To answer this question, I need to first find all the emails related to the Paper reading invitation. I will use the 'search_query' tool to fetch relevant emails. After that, I'll look into those emails to find out the researchers who accepted and declined the invitation. Once I have their email addresses, I can use the 'find_conversations' tool to get the full context of each conversation, which should include the researchers' papers....\n",
      "Thought: The search results show four email threads related to the Paper reading invitation - one from John Doe accepting the invitation, and three invitations sent to Alice, Bob, and Jane. I need to find the responses from Alice, Bob, and Jane to determine whether they accepted or declined the invitation. I will once again use the 'search_query' tool to look for their responses specifically....\n",
      "Thought: The search results only show the original invitations for Alice, Bob, and Jane, but not their responses. I will use the 'find_conversations' tool to see the full conversations with each of them with a common subject line containing \"Paper reading invitation.\"...\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 3 column 16 (char 52)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-7a8fcae4ade1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Who are the researchers (and their papers) that accepted and declined my Paper reading invitation?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-55-53b8cf222696>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mips\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"search_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"query\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mips\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 3 column 16 (char 52)"
     ]
    }
   ],
   "source": [
    "prompt = \"Who are the researchers (and their papers) that accepted and declined my Paper reading invitation?\"\n",
    "generate_response(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CekFl78MTS09"
   },
   "source": [
    "Here the failure occured because Mixtral didn't generate the function arguments in the format we had specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P9SpqL2DjUYB"
   },
   "source": [
    "#### To summarise\n",
    "Adhering to system prompt instructions is challenging for large language models (LLMs) and requires meticulous fine-tuning. Key observations include:\n",
    "\n",
    "* **Model-Specific Prompting:** Effective prompts for one model may not work for another, necessitating model-specific adjustments.\n",
    "* **Prompt Refinement:** The failure of llama-2-70b-chat to include \"Action Input\" suggests the need for further prompt refinement for compatibility.\n",
    "* **Format Adherence:** Mixtral's failure to generate the specified function arguments highlights the importance of precise prompt structuring.\n",
    "\n",
    "These findings underscore the complexity of creating universal prompts and the need for adaptable prompting strategies to ensure consistent model responses."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
